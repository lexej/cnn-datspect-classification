\section{Evaluation}
\label{sec:evaluation}

The preceding chapters have detailed the research methodology, data collection and sources, and the application of classification techniques 
to address the research questions posed in this study. 

This chapter embarks on the evaluation of the research results, focusing on the performance and effectiveness of the methods employed, 
and the attainment of the research objectives.

The structure of this chapter has been designed to systematically lead readers through the assessment process. 
It commences with an examination of the significant performance metrics utilized for the evaluation of 
the research outcomes.
The core of this chapter subsequently unveils the experimental results 
for baseline and experimental methods evaluated using various test datasets. 
These findings are presented using performance summary tables for statistical measures and graphical representations.
The chapter culminates with a comparative analysis, which seeks to assess and contrast the effectiveness and 
limitations of the research methods employed.


\subsection{Evaluation Metrics and Procedure}
\label{subsec:determinationInconcl}

In the following the performance metrics used for the evaluation of the different classification methods 
are explained in more detail.

First the $\text{mean} \pm \text{SD}$ (standard deviation) of the following measures were calculated across
the different random splits for each classification approach and subset (training, validation and testing) given a cutoff: 
Area Under Curve (AUC) for ROC curve, Balanced accuracy, accuracy, sensitivity, specificity, 
Positive Predictive Value (PPV) and Negative Predictive Value (NPV).
The natural cutoff of 0.5 was used for each classification approach except the SBR method.
For the SBR method the optimal cutoff was determined using the Youden criterion~\citep{Youden1950} and was used for
calculating the measures.
Majority vote was used as strategy to assign labels for cases in which no between-reader consensus could be achieved.

% Determination of inconclusive intervals given set of percentages of inconclusive cases
Second for each element within a set of considered percentages of inconclusive cases in the validation set 
the corresponding inconclusive interval was determined.
Inconclusive cases were defined as cases predicted within an inconclusive interval 
(bounded by lower and upper bound), while conclusive cases were those predicted outside this interval.
The determination of the inconclusive interval was exclusively performed using the validation set 
for each random split and classification approach independently.
The set of percentages of inconclusive cases considered ranged from 0.2\% to 20.0\%, increasing in increments of 0.2\%.
For each target percentage of inconclusive cases in the set the lower and upper bounds of the inconclusive interval 
were independently determined in such a way that there was a similar number of inconclusive cases both below and above 
the pre-defined cutoff.
For the CNN-based classification approaches (described in Section~\ref{subsec:cnn_based_classification}) and the 
multivariate benchmark (described in Section~\ref{subsec:pca_rfc}) the natural cutoff of 0.5 was used.
For the SBR-based univariate benchmark (described in Section~\ref{subsec:sbr}), 
the optimal cutoff on the SBR obtained by applying the Youden criterion~\citep{Youden1950} using ROC analysis was used.

% Stability of inconclusive interval
To assess the stability of the determined inconclusive interval over the proportion of inconclusive cases
the determined upper and lower bounds ($\text{mean} \pm \text{SD}$) of the inconclusive interval
were plotted against the corresponding proportion of inconclusive cases (\%) in the validation set.
The $\text{mean} \pm \text{SD}$ of determined upper and lower bounds was calculated across the measures for 
different random splits.
The rate at which the lower (upper) bound decreases (increases) in relation to the proportion of inconclusive 
cases reflects the density of inconclusive cases around the cutoff.
Specifically, higher function gradients indicate lower concentration of predictions around the cutoff, 
and vice versa.
The measurement was conducted separately for each classification approach.

% AUC of bal_acc vs. %inconclusive_cases; determination of inconclusive ranges for each %inconclusive_cases

The main performance metric used in this work to evaluate and compare the classification approaches was 
the area under the curve (AUC) of mean balanced accuracy (\%) on conclusive test cases as a function of 
the proportion of inconclusive test cases (\%, mean).
More precisely the relative AUC (\%) normalized to the maximum achievable area was used for the comparison.
To obtain the relative AUC, 
first, the mean balanced accuracy function was interpolated using cubic spline interpolation.
Then the area under the mean balanced accuracy curve was computed using the trapezoidal rule 
and then normalized to the maximum achievable area.
The evaluation of each classification method with respect to this metric was conducted on the test set of the 
development dataset as well as on the independent datasets PPMI and MPH.


% Proportion of inconclusive cases in test set vs. 
Also the observed $\text{mean} \pm \text{SD}$ proportion of inconclusive cases in the test set was plotted 
against the proportion of inconclusive cases in the validation set.
% WHY? Explain what would indicate desired behaviour and what not


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Baseline Performance}
\label{subsec:baseline_performance}

In this section, the performance of the SBR method, a widely recognized technique in the field, 
is thoroughly evaluated. 
Furthermore the outcomes for the random forest based method PCA-RFC are also provided as additional baseline.
The objective of this evaluation is twofold: to comprehend the inherent capabilities of the baseline methods, SBR and
PCA-RFC, and to establish a clear point of reference for the CNN-based methodologies.

\subsubsection{SBR Method Results}
\label{subsubsec:eval_sbr}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset


Table~\ref{t1:sbr_perf_eval_table} presents the quantitative performance 
(Balanced accuracy, accuracy, sensitivity, specificity, PPV, NPV and AUC-ROC) of the SBR-based classification on the 
particular subset of the Development dataset.
In the evaluation process, the optimal SBR cutoff value of 0.703 (with a variation of $\pm$0.009 across random splits) 
was employed.
The SBR method consistently achieves around 93\% in balanced accuracy, accuracy, sensitivity, specificity, PPV and NPV 
on the training set, with a variance around 0.5\% across random splits.
The performance on validation and test set is also around 93\% with respect to all the metrics
with a slightly higher variance across random splits (0.5-2\%) compared to training set.
The comparable sensitivity and specificity imply a well-balanced SBR model which 
identifies both positive and negative cases similarly well.
The SBR model achieves a stable AUC-ROC of 0.983$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the SBR method on Development dataset (SBR cutoff mean$\pm$SD: 0.703$\pm$0.009).}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.936$\pm$0.003   &   0.929$\pm$0.008   &  0.935$\pm$0.007     \\
      Accuracy          & 0.936$\pm$0.003   &   0.930$\pm$0.008   &  0.935$\pm$0.007     \\
      Sensitivity       &  0.934$\pm$0.006  &   0.924$\pm$0.005   &  0.930$\pm$0.014     \\
      Specificity       & 0.937$\pm$0.003   &   0.935$\pm$0.015   &  0.939$\pm$0.012     \\
      PPV               &  0.933$\pm$0.005  &   0.929$\pm$0.014   &  0.930$\pm$0.015     \\
      NPV               &  0.938$\pm$0.005  &   0.930$\pm$0.004   &  0.938$\pm$0.018     \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.983$\pm$0.002 }  \\
      \hline
  \end{tabular}
 \label{t1:sbr_perf_eval_table}
\end{table}


As the next step in the course of the evaluation, 
the respective inconclusive interval bounds were determined 
for each element within a range of predefined percentages of inconclusive cases 
in the validation set (development dataset).
Figure~\ref{fig:sbr_percInconclCases_development} illustrates the determined lower and upper bounds on the SBR 
as a function of the percentages of inconclusive cases in the validation set, 
along with the mean$\pm$SD of the optimal cutoff.
Corroborating the intuitive expectation, the width of the inconclusive interval expands 
as the percentage of inconclusive cases increases.
The close resemblance in slopes between the upper and lower bound functions 
indicates a nearly identical distribution of predictions both below and above the cutoff.

Thereafter the determined inconclusive intervals (mean lower and upper bounds) per percentage of inconclusive cases 
in validation set (development dataset)
are used to calculate the corresponding percentage of observed inconclusive cases in the test set (development dataset).
In Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_development} the correspondence between 
the percentage of inconclusive cases in the validation set and 
the mean$\pm$SD percentage of observed inconclusive cases in the test set is demonstrated.
The plot illustrates that the deviation of the mean percentage of observed inconclusive cases in the test set from the 
identity line is negligibly small.
This can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting) which results in a similar distribution of SBR model predictions.


% sbr_percInconclCases_development
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{content/figures/evaluations/sbr/86/sbr_percInconclCases_development.png}
    \caption{Evaluation of the SBR method on Test Set of Development dataset. 
    Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
    \label{fig:sbr_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_sbr_development
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_development.png}
    \caption{Evaluation of the SBR method on Test Set of Development dataset.
    Observed percentage of inconclusive cases in the test set 
    for a given set of percentages of inconclusive cases in the validation set.
    Each of the percentages of inconclusive cases in the validation set is associated 
    with an inconclusive range (determined in the validation set).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_development}
\end{figure} 


After determining the set of mean percentages of observed inconclusive cases in the test set (development dataset), 
balanced accuracy is computed for each mean percentage corresponding to a specific inconclusive interval.
Figure~\ref{fig:bacc_obsInconclCases_sbr_development} shows the balanced accuracy (mean$\pm$SD across random splits) 
on both conclusive and inconclusive cases as a function of the mean percentage of observed inconclusive cases 
in the test set (development dataset).
The balanced accuracy on inconclusive cases is not part of further performance analysis and comparison 
due to the emphasis on the balanced accuracy on conclusive cases as the basis for the main metric of this work.

The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean percentage of observed inconclusive cases 
is depicted with enhanced clarity and precision in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_development}.
The mean of the balanced accuracy rises from approximately 94\% 
when there are around 1\% of inconclusive cases in the test set to about 98\% 
when there are around 20\% of inconclusive cases in the test set.
The SBR baseline method attains a relative AUC of 96.38\% for the mean balanced accuracy on conclusive cases
over the mean percentage of observed inconclusive cases in the test set of the development dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.

% bacc_obsInconclCases_sbr_development_full
\begin{figure}[ht]
    \begin{subfigure}{0.9\textwidth}
      \centering
      \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_sbr_development.png}
      \subcaption{}
      \label{fig:bacc_obsInconclCases_sbr_development}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
      \centering
      \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_development.png}
      \subcaption{}
      \label{fig:bacc_obsInconclCases_concl_sbr_development}
    \end{subfigure}

    \caption{Evaluation of the SBR method on Test Set of Development dataset.
    Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
    (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
    Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
    \label{fig:bacc_obsInconclCases_sbr_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

The SBR method was also evaluated on the independent test datasets PPMI and MPH.
The performance results for the SBR method on the PPMI test dataset are depicted in Figure~\ref{fig:perf_results_sbr_ppmi} 
whereas Figure~\ref{fig:perf_results_sbr_mph} presents the results for the SBR method on the MPH test dataset.

% ---------------- PPMI ---------------------

The mean$\pm$SD percentage of inconclusive cases observed in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset) 
is consistently below the identity line, 
which can be seen in Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_ppmi}.
That implies that the SBR method produces relatively fewer inconclusive cases for the PPMI dataset  
in comparison to the validation set and thus exhibits higher prediction confidence on the PPMI dataset, 
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_ppmi}.
The mean of the balanced accuracy rises from approximately 96\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The SBR baseline method achieves a relative AUC of 97.51\% for the mean balanced accuracy on conclusive cases 
over the mean percentage of observed inconclusive cases in the PPMI test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_sbr_ppmi and bacc_obsInconclCases_concl_sbr_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_sbr_ppmi}
  \end{subfigure}
  \caption{Evaluation of the SBR method on PPMI dataset.}
  \label{fig:perf_results_sbr_ppmi}
\end{figure}



% -------------- MPH -----------------

The evaluation of the SBR method on the MPH dataset shows the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_mph} demonstrates 
the mean$\pm$SD percentage of inconclusive cases observed in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
Similar as in case of the PPMI dataset, here the percentage of inconclusive cases observed in the MPH test dataset
is also consistently below the identity line.
Therefore the SBR method produces relatively fewer inconclusive cases for the MPH dataset  
in comparison to the validation set and thus exhibits higher prediction confidence on the MPH dataset, 
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_mph}.
The mean of the balanced accuracy rises from approximately 91.5\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 95\% 
when there are around 20\% of inconclusive cases in the MPH test set.
The SBR baseline method achieves a relative AUC of 93.46\% for the mean balanced accuracy on conclusive cases 
over the mean percentage of observed inconclusive cases in the MPH test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_sbr_mph and bacc_obsInconclCases_concl_sbr_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_sbr_mph}
  \end{subfigure}
  \caption{Evaluation of the SBR method on MPH dataset.}
  \label{fig:perf_results_sbr_mph}
\end{figure}

% Write summary of performance on dev test, ppmi and mph and compare


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{PCA-RFC Method Results}
\label{subsubsec:eval_rfc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset

Table~\ref{t1:erc_perf_eval_table} presents the quantitative performance 
(Balanced accuracy, accuracy, sensitivity, specificity, PPV, NPV and AUC-ROC) of the PCA-RFC classification on the 
particular subset of the Development dataset.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The PCA-RFC method achieves around 96\% in balanced accuracy, accuracy, sensitivity, specificity, PPV and NPV 
on the validation and test set, with a variance around 1\% across random splits.
The SBR model achieves a stable AUC-ROC of 0.994$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the PCA-RFC method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 1.000$\pm$0.000   &   0.963$\pm$0.010    &  0.966$\pm$0.006   \\
      Accuracy          & 1.000$\pm$0.000    &   0.963$\pm$0.010  &  0.966$\pm$0.006    \\
      Sensitivity       &  1.000$\pm$0.000   &   0.957$\pm$0.012   &  0.962$\pm$0.010   \\
      Specificity       & 1.000$\pm$0.000    &   0.969$\pm$0.011  &  0.969$\pm$0.009   \\
      PPV               &  1.000$\pm$0.000   &   0.966$\pm$0.012   &  0.965$\pm$0.010   \\
      NPV               &  1.000$\pm$0.000   &   0.961$\pm$0.012  &  0.966$\pm$0.011   \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.994$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:erc_perf_eval_table}
\end{table}

Figure~\ref{fig:pca_rfc_percInconclCases_development} illustrates the determined lower and upper bounds on the 
probabilistic output as a function of the percentages of inconclusive cases in the validation set (development dataset), 
along with the natural cutoff of $0.5$.
The width of the inconclusive interval expands as the percentage of inconclusive cases increases 
and the visual resemblance in shape and slope between the curve a similar distribution of predictions both below and above the cutoff.

The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases in the test set (development dataset) 
is demonstrated in Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_development}.
The deviation of the mean percentage of observed inconclusive cases in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% pca_rfc_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/pca_rfc/86/sigmoid_percInconclCases_pca_rfc_development.png}
  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:pca_rfc_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_pca_rfc_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_development.png}
  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_development}
\end{figure} 


Figure~\ref{fig:bacc_obsInconclCases_pca_rfc_development} shows the balanced accuracy (mean$\pm$SD across random splits) 
on both conclusive and inconclusive cases as a function of the mean percentage of observed inconclusive cases 
in the test set (development dataset).
The balanced accuracy on inconclusive cases is not part of performance analysis and comparison 
due to the emphasis on the balanced accuracy on conclusive cases as the basis for the main metric of this work.

The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean percentage of observed inconclusive cases 
is depicted with enhanced clarity and precision in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_development}.
The mean of the balanced accuracy rises from approximately 97\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the PCA-RFC baseline method achieves a relative AUC of 98.71\% for the mean balanced accuracy on conclusive cases
over the mean percentage of observed inconclusive cases in the test set of the development dataset.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_pca_rfc_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_pca_rfc_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_pca_rfc_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_development}
  \end{subfigure}

  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_pca_rfc_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

The PCA-RFC baseline method was also evaluated on the independent test datasets PPMI and MPH.
The performance results for the PCA-RFC method on the PPMI test dataset are presented in Figure~\ref{fig:perf_results_rfc_ppmi} 
whereas Figure~\ref{fig:perf_results_rfc_mph} presents the results for the PCA-RFC method on the MPH test dataset.


% ---------------- PPMI ---------------------

The following results were obtained when evaluating the PCA-RFC method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_ppmi} shows the
mean$\pm$SD percentage of inconclusive cases observed in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
The function is consistently above the identity line which implies that the PCA-RFC method 
produces relatively more inconclusive cases for the PPMI dataset  
in comparison to the validation set and thus exhibits lower prediction confidence on the PPMI dataset, 
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases is presented 
in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_ppmi}.
The mean of the balanced accuracy rises from approximately 98\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The PCA-RFC baseline method achieves a relative AUC of 99.12\% for the mean balanced accuracy on conclusive cases 
over the mean percentage of observed inconclusive cases in the PPMI test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_pca_rfc_ppmi and bacc_obsInconclCases_concl_pca_rfc_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_ppmi}
  \end{subfigure}
  \caption{Evaluation of the PCA-RFC method on PPMI dataset.}
  \label{fig:perf_results_rfc_ppmi}
\end{figure}



% -------------- MPH -----------------


The evaluation of the PCA-RFC method on the MPH dataset shows the following results.
In Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_mph} 
the mean$\pm$SD percentage of inconclusive cases observed in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (development dataset) is illustrated.
As in the PPMI case, the percentage of inconclusive cases observed in the MPH test dataset
is also above the identity line however the deviation is much stronger.
Therefore the PCA-RFC method produces relatively much more inconclusive cases for the MPH dataset  
in comparison to the validation set.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_mph}.
The mean of the balanced accuracy rises from approximately 90.5\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 94\% 
when there are around 19\% of inconclusive cases in the MPH test set.
As a result, the PCA-RFC baseline method achieves a relative AUC of 92.42\% for the mean balanced accuracy on conclusive cases 
over the mean percentage of observed inconclusive cases in the MPH test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_pca_rfc_mph and bacc_obsInconclCases_concl_pca_rfc_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_mph}
  \end{subfigure}
  \caption{Evaluation of the PCA-RFC method on MPH dataset.}
  \label{fig:perf_results_rfc_mph}
\end{figure}


\subsection{Experimental Methods Performance}
\label{subsec:exp_methods_perf}

This section presents the performance results for the CNN-based classification approaches sepertatly and compares them 
to the results obtained by the baseline approaches.
First the results for the CNN-MVT method are presented, whereafter the CNN-RLT method is evaluated.
Finally the findings for the CNN-Regression method are showcasted.

\subsubsection{CNN-MVT Method Results}
\label{subsubsec:eval_mvt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset

The quantitative performance results of the CNN-MVT classification on the 
particular subset of the Development dataset are presented in Table~\ref{t1:cnn_mvt_perf_eval_table}.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The CNN-MVT method achieves around 96.4\% in sensitivity, 97.6\% in specificity and a balanced accuracy of 97.0\%, 
with a variance between 1-2\% across random splits, on the test set.
The performance results on the validation set are very similar.
The method achieves a stable AUC-ROC of 0.996$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the CNN-MVT method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.999$\pm$0.003   &  0.970$\pm$0.014    &  0.970$\pm$0.008   \\
      Accuracy          & 0.999$\pm$0.003    &   0.970$\pm$0.014   &  0.970$\pm$0.008   \\
      Sensitivity       &  1.000$\pm$0.000   &   0.963$\pm$0.010   &  0.964$\pm$0.015  \\
      Specificity       &   0.997$\pm$0.006   &   0.976$\pm$0.023  &   0.976$\pm$0.013  \\
      PPV               &  0.997$\pm$0.006   &   0.975$\pm$0.024   &  0.972$\pm$0.018 \\
      NPV               &  1.000$\pm$0.000    &   0.966$\pm$0.010   & 0.968$\pm$0.014  \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.996$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_mvt_perf_eval_table}
\end{table}


In Figure~\ref{fig:baseline_majority_percInconclCases_development} the determined lower and upper bounds on the 
probabilistic sigmoid output are plotted as a function of the percentages of inconclusive cases 
in the validation set (development dataset), along with the natural cutoff $0.5$.
The visual resemblance in shape and slope between the upper and lower bound curves 
indicates a similar distribution of predictions both below and above the cutoff.
The width of the inconclusive interval increases more rapidly as the percentage of inconclusive cases increases 
when compared to the PCA-RFC baseline method.
That implies that the CNN-MVT method produces relatively less inconclusive cases than the PCA-RFC baseline.


The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases in the test set (development dataset) 
is illustrated in Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_development}.
As for the baseline cases, the deviation of the mean percentage of observed inconclusive cases in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% baseline_majority_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_majority/86/sigmoid_percInconclCases_baseline_majority_development.png}
  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:baseline_majority_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_baseline_majority_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_development.png}
  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_development}
\end{figure} 


The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean percentage of observed inconclusive cases 
in the test set (development dataset) 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_development}.
The mean of the balanced accuracy rises from about 97\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the CNN-MVT method achieves a relative AUC of 98.95\% for the mean balanced accuracy on conclusive cases
over the mean percentage of observed inconclusive cases in the test set of the development dataset.
The achieved relative AUC is approximately 2.5\% higher than that of the SBR baseline method 
and around 0.2\% higher than the PCA-RFC baseline.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_baseline_majority_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_baseline_majority_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_baseline_majority_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_baseline_majority_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

The CNN-MVT method was also evaluated on the independent test datasets PPMI and MPH.
The performance results for the CNN-MVT method on the PPMI test dataset are presented in Figure~\ref{fig:perf_results_mvt_ppmi} 
whereas Figure~\ref{fig:perf_results_mvt_mph} presents the results for the CNN-MVT method on the MPH test dataset.


% ---------------- PPMI ---------------------


The following results were obtained when evaluating the CNN-MVT method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_ppmi} depicts the
mean$\pm$SD percentage of inconclusive cases observed in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
For lower percentages of inconclusive cases in the validation set the corresponding 
percentages of observed inconclusive cases in the PPMI test dataset are similar.
However for higher percentages of inconclusive cases (corresponding to braoder inconclusive intervals) 
in the validation set the method produces relatively more inconclusive cases for the PPMI dataset 
and thus exhibits less confidence.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases is illustrated 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_ppmi}.
The mean of the balanced accuracy rises from approximately 98\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The CNN-MVT method achieves a relative AUC of 99.23\% for the mean balanced accuracy on conclusive cases 
over the mean percentage of observed inconclusive cases in the PPMI test dataset.
The achieved relative AUC is approximately 1.7\% higher than that of the SBR baseline method 
and around 0.1\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_majority_ppmi and bacc_obsInconclCases_concl_baseline_majority_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-MVT method on PPMI dataset.}
  \label{fig:perf_results_mvt_ppmi}
\end{figure}


% -------------- MPH -----------------


The evaluation of the CNN-MVT method on the MPH dataset produced the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_mph} presents
the mean$\pm$SD percentage of inconclusive cases observed in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
The mean of the percentage of inconclusive cases observed in the MPH test dataset
is above the identity line 
and increases as the percentage of inconclusive cases in the validation set increases.
The standard deviation also increases over the percentage of inconclusive cases in the validation set.
When compared to the SBR baseline the CNN-MVT method shows a stronger misalignment between 
the percentage of inconclusive cases in validation and test set. 
However compared to the PCA-RFC baseline the CNN-MVT method exhibits better alignment.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases is depicted 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_mph}.
The mean of the balanced accuracy increases from approximately 95\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 96\% 
when there are around 20\% of inconclusive cases in the MPH test set.
As a result, the CNN-MVT method achieves a relative AUC of 95.73\% for the mean balanced accuracy on conclusive cases 
over the mean percentage of observed inconclusive cases in the MPH test dataset.
The achieved relative AUC is approximately 2.3\% higher than that of the SBR baseline method 
and around 3.3\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_majority_mph and bacc_obsInconclCases_concl_baseline_majority_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-MVT method on MPH dataset.}
  \label{fig:perf_results_mvt_mph}
\end{figure}


\subsubsection{CNN-RLT Method Results}
\label{subsubsec:eval_rlt}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset


\begin{table}[ht]
  \caption{Evaluation of the CNN-RLT method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.982$\pm$0.003   &  0.967$\pm$0.008    &  0.973$\pm$0.005  \\
      Accuracy          & 0.982$\pm$0.003    &   0.968$\pm$0.008   &  0.973$\pm$0.005  \\
      Sensitivity       &  0.980$\pm$0.008  &   0.951$\pm$0.013  &  0.961$\pm$0.014 \\
      Specificity       &   0.983$\pm$0.008   &   0.984$\pm$0.005  &   0.985$\pm$0.010 \\
      PPV               &  0.983$\pm$0.009   &   0.982$\pm$0.006   &  0.982$\pm$0.012   \\
      NPV               &  0.981$\pm$0.008   &   0.956$\pm$0.012   & 0.966$\pm$0.013  \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.994$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_rlt_perf_eval_table}
\end{table}


% baseline_random_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_random/86/sigmoid_percInconclCases_baseline_random_development.png}
  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:baseline_random_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_baseline_random_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_development.png}
  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_baseline_random_development}
\end{figure} 


% bacc_obsInconclCases_baseline_random_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_baseline_random_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_baseline_random_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_baseline_random_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

% ---------------- PPMI ---------------------

% obsInconclCases_inconclCasesValid_baseline_random_ppmi and bacc_obsInconclCases_concl_baseline_random_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_random_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-RLT method on PPMI dataset.}
\end{figure}



% -------------- MPH -----------------


% obsInconclCases_inconclCasesValid_baseline_random_mph and bacc_obsInconclCases_concl_baseline_random_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_random_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-RLT method on MPH dataset.}
\end{figure}


\subsubsection{CNN-Regression Method Results}
\label{subsubsec:eval_regression}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset


\begin{table}[ht]
  \caption{Evaluation of the CNN-Regression method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.982+/-0.003   &  0.977+/-0.006    &  0.975+/-0.006 \\
      Accuracy          & 0.980+/-0.003     &   0.977+/-0.007   &  0.976+/-0.006  \\
      Sensitivity       &  1.000+/-0.000   &   0.983+/-0.009   &  0.961+/-0.011 \\
      Specificity       &   0.963+/-0.005  &   0.972+/-0.009 &   0.988+/-0.008 \\
      PPV               &  0.960+/-0.005    &   0.967+/-0.011  &  0.986+/-0.009  \\
      NPV               &  1.000+/-0.000  &   0.985+/-0.008   & 0.967+/-0.010 \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.998+/-0.001}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_regression_perf_eval_table}
\end{table}


% regression_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/regression/86/sigmoid_percInconclCases_regression_development.png}
  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:regression_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_regression_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_development.png}
  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_regression_development}
\end{figure} 


% bacc_obsInconclCases_regression_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_regression_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_regression_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_regression_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_regression_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

% ---------------- PPMI ---------------------

% obsInconclCases_inconclCasesValid_regression_ppmi and bacc_obsInconclCases_concl_regression_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_regression_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_regression_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-Regression method on PPMI dataset.}
\end{figure}



% -------------- MPH -----------------


% obsInconclCases_inconclCasesValid_regression_mph and bacc_obsInconclCases_concl_regression_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_regression_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_regression_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-Regression method on MPH dataset.}
\end{figure}


\subsection{Comparative Analysis}
\label{subsec:compar_anal}


\subsubsection{Comparison of Performance on Test set of Development dataset}
\label{subsubsec:perf_comp_dev}


% Method Comparison of obsInconclCases_inconclCasesValid - Development test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_development.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_development.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_development.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_development.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_development.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on test set of development data. Inconclusive interval matching.}
  \label{fig:test_interval_match_dev}
\end{figure}

% Method Comparison of bacc-obsInconclCases-concl - Development test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_development.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_development.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_development.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_development.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_development.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on test set of development data.}
  \label{fig:test_dev}
\end{figure}



\subsubsection{Comparison of Performance on Independent datasets}
\label{subsubsec:perf_comp_indep}


% ------ PPMI --------


% Method Comparison of obsInconclCases_inconclCasesValid - PPMI
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_ppmi.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_ppmi.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_ppmi.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_ppmi.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_ppmi.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on PPMI dataset. Inconclusive interval matching.}
  \label{fig:test_interval_match_ppmi}
\end{figure}


% Method Comparison of bacc_obsInconclCases_concl - PPMI test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_ppmi.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_ppmi.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_ppmi.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_ppmi.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_ppmi.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on PPMI dataset.}
  \label{fig:test_ppmi}
\end{figure}


% ------ MPH --------

% Method Comparison of obsInconclCases_inconclCasesValid - MPH
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_mph.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_mph.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_mph.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_mph.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_mph.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on MPH dataset. Inconclusive interval matching.}
  \label{fig:test_interval_match_mph}
\end{figure}


% Method Comparison of bacc_obsInconclCases_concl - MPH test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_mph.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_mph.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_mph.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_mph.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_mph.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on MPH dataset.}
  \label{fig:test_mph}
\end{figure}



% AUC bAcc comparison of different methods and dataset
\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/auc_main_comparison.png}
  \caption{Comparison of AUC achieved by each method on different test data. 
  The AUC was calculated for the mean balanced accuracy over the percentage of inconclusive cases 
  in the considered test set.} 
  \label{fig:auc_comparison_methods_data}
\end{figure} 