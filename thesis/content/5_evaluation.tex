\section{Evaluation}
\label{sec:evaluation}

The preceding chapters have detailed the research methodology, data collection and sources, and the application of classification techniques 
to address the research questions posed in this study. 

This chapter embarks on the evaluation of the research results, focusing on the performance and effectiveness of the methods employed, 
and the attainment of the research objectives.

The structure of this chapter has been designed to systematically lead readers through the assessment process. 
The chapter commences with the examination of the performance results obtained for the baseline methods.
The core of this chapter subsequently unveils the results 
for the experimental methods evaluated using various test datasets and compared to the baseline performance.
These findings are presented using performance summary tables for statistical measures and graphical representations.
The chapter culminates with a comparative analysis, which seeks to assess and contrast the effectiveness and 
limitations of the research methods employed.

\subsection{Baseline Performance}
\label{subsec:baseline_performance}

In this section, the performance of the SBR method, a widely recognized technique in the field, 
is thoroughly evaluated. 
Furthermore the outcomes for the multivariate PCA-RFC method are also provided as additional baseline.
The objective of this evaluation is twofold: to comprehend the inherent capabilities of the baseline methods, SBR and
PCA-RFC, and to establish a clear point of reference for the CNN-based methodologies.

\subsubsection{SBR Method Results}
\label{subsubsec:eval_sbr}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Test set of Development dataset}

% Evaluation on Development dataset
\subparagraph{Binary classification performance}

Table~\ref{t1:sbr_perf_eval_table} presents the quantitative performance 
(Balanced accuracy, accuracy, sensitivity, specificity, PPV, NPV and AUC-ROC) of the SBR-based classification on the 
particular subset of the Development dataset.
In the evaluation process, the optimal SBR cutoff value of 0.703 (with a variation of $\pm$0.009 across random splits) 
was employed.
The SBR method consistently achieves around 93\% in balanced accuracy, accuracy, sensitivity, specificity, PPV and NPV 
on the training set, with a variance around 0.5\% across random splits.
The performance on validation and test set is also around 93\% with respect to all the metrics
with a slightly higher variance across random splits (0.5-2\%) compared to training set.
The comparable sensitivity and specificity imply a well-balanced SBR model which 
identifies both positive and negative cases similarly well.
The SBR model achieves a stable AUC-ROC of 0.983$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the SBR method on Development dataset (SBR cutoff mean$\pm$SD: 0.703$\pm$0.009).}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.936$\pm$0.003   &   0.929$\pm$0.008   &  0.935$\pm$0.007     \\
      Accuracy          & 0.936$\pm$0.003   &   0.930$\pm$0.008   &  0.935$\pm$0.007     \\
      Sensitivity       &  0.934$\pm$0.006  &   0.924$\pm$0.005   &  0.930$\pm$0.014     \\
      Specificity       & 0.937$\pm$0.003   &   0.935$\pm$0.015   &  0.939$\pm$0.012     \\
      PPV               &  0.933$\pm$0.005  &   0.929$\pm$0.014   &  0.930$\pm$0.015     \\
      NPV               &  0.938$\pm$0.005  &   0.930$\pm$0.004   &  0.938$\pm$0.018     \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.983$\pm$0.002 }  \\
      \hline
  \end{tabular}
 \label{t1:sbr_perf_eval_table}
\end{table}

\subparagraph{Determined Inconclusive Intervals}

Figure~\ref{fig:sbr_percInconclCases_development} illustrates the determined lower and upper bounds on the SBR 
as a function of the percentages of inconclusive cases in the validation set (development dataset), 
along with the mean$\pm$SD of the optimal cutoff.
Corroborating the intuitive expectation, the width of the inconclusive interval expands 
as the percentage of inconclusive cases increases.
The close resemblance in slopes between the upper and lower bound functions 
indicates a nearly identical distribution of predictions both below and above the cutoff.

\subparagraph{Inconclusive Interval Correspondence}

In Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_development} the correspondence between 
the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) is demonstrated.
The plot illustrates that the deviation of the mean PIncObs in the test set from the 
identity line is negligibly small.
This can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting) which results in a similar distribution of SBR model predictions.


% sbr_percInconclCases_development
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{content/figures/evaluations/sbr/86/sbr_percInconclCases_development.png}
    \caption{Evaluation of the SBR method on Test Set of Development dataset. 
    Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
    \label{fig:sbr_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_sbr_development
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_development.png}
    \caption{Evaluation of the SBR method on Test Set of Development dataset.
    Observed percentage of inconclusive cases in the test set 
    for a given set of percentages of inconclusive cases in the validation set.
    Each of the percentages of inconclusive cases in the validation set is associated 
    with an inconclusive range (determined in the validation set).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_development}
\end{figure} 

\subparagraph{AUC for Balanced Accuracy over PIncObs}

Figure~\ref{fig:bacc_obsInconclCases_sbr_development} shows the balanced accuracy (mean$\pm$SD across random splits) 
on both conclusive and inconclusive cases as a function of the mean PIncObs
in the test set (development dataset).
The balanced accuracy on inconclusive cases is not part of further performance analysis and comparison 
due to the emphasis on the balanced accuracy on conclusive cases as the basis for the main metric of this work.
The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs
is depicted with enhanced clarity and precision in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_development}.
The mean of the balanced accuracy rises from approximately 94\% 
when there are around 1\% of inconclusive cases in the test set to about 98\% 
when there are around 20\% of inconclusive cases in the test set.
The SBR baseline method attains a relative AUC of 96.38\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.

% bacc_obsInconclCases_sbr_development_full
\begin{figure}[ht]
    \begin{subfigure}{0.9\textwidth}
      \centering
      \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_sbr_development.png}
      \subcaption{}
      \label{fig:bacc_obsInconclCases_sbr_development}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
      \centering
      \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_development.png}
      \subcaption{}
      \label{fig:bacc_obsInconclCases_concl_sbr_development}
    \end{subfigure}

    \caption{Evaluation of the SBR method on Test Set of Development dataset.
    Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
    (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
    Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
    \label{fig:bacc_obsInconclCases_sbr_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

% ---------------- PPMI ---------------------

\paragraph{PPMI dataset}

The results obtained from evaluating the SBR method on the PPMI dataset 
are depicted in Figure~\ref{fig:perf_results_sbr_ppmi}.
The mean$\pm$SD percentage of inconclusive cases observed in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset) 
is consistently below the identity line, 
which can be seen in Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_ppmi}.
That implies that the SBR method produces relatively fewer inconclusive cases for the PPMI dataset  
in comparison to the validation set and thus exhibits higher prediction confidence on the PPMI dataset, 
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_ppmi}.
The mean of the balanced accuracy rises from approximately 96\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The SBR baseline method achieves a relative AUC of 97.51\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_sbr_ppmi and bacc_obsInconclCases_concl_sbr_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_sbr_ppmi}
  \end{subfigure}
  \caption{Evaluation of the SBR method on PPMI dataset.}
  \label{fig:perf_results_sbr_ppmi}
\end{figure}



% -------------- MPH -----------------

\paragraph{MPH dataset}

The evaluation of the SBR method on the MPH dataset is shown in Figure~\ref{fig:perf_results_sbr_mph}.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_mph} demonstrates 
the mean$\pm$SD percentage of inconclusive cases observed in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
Similar as in case of the PPMI dataset, here the percentage of inconclusive cases observed in the MPH test dataset
is also consistently below the identity line.
Therefore the SBR method produces relatively fewer inconclusive cases for the MPH dataset  
in comparison to the validation set and thus exhibits higher prediction confidence on the MPH dataset, 
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_mph}.
The mean of the balanced accuracy rises from approximately 91.5\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 95\% 
when there are around 20\% of inconclusive cases in the MPH test set.
The SBR baseline method achieves a relative AUC of 93.46\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_sbr_mph and bacc_obsInconclCases_concl_sbr_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_sbr_mph}
  \end{subfigure}
  \caption{Evaluation of the SBR method on MPH dataset.}
  \label{fig:perf_results_sbr_mph}
\end{figure}

% Write summary of performance on dev test, ppmi and mph and compare


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{PCA-RFC Method Results}
\label{subsubsec:eval_rfc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset

Table~\ref{t1:erc_perf_eval_table} presents the quantitative performance 
(Balanced accuracy, accuracy, sensitivity, specificity, PPV, NPV and AUC-ROC) of the PCA-RFC classification on the 
particular subset of the Development dataset.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The PCA-RFC method achieves around 96\% in balanced accuracy, accuracy, sensitivity, specificity, PPV and NPV 
on the validation and test set, with a variance around 1\% across random splits.
The SBR model achieves a stable AUC-ROC of 0.994$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the PCA-RFC method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 1.000$\pm$0.000   &   0.963$\pm$0.010    &  0.966$\pm$0.006   \\
      Accuracy          & 1.000$\pm$0.000    &   0.963$\pm$0.010  &  0.966$\pm$0.006    \\
      Sensitivity       &  1.000$\pm$0.000   &   0.957$\pm$0.012   &  0.962$\pm$0.010   \\
      Specificity       & 1.000$\pm$0.000    &   0.969$\pm$0.011  &  0.969$\pm$0.009   \\
      PPV               &  1.000$\pm$0.000   &   0.966$\pm$0.012   &  0.965$\pm$0.010   \\
      NPV               &  1.000$\pm$0.000   &   0.961$\pm$0.012  &  0.966$\pm$0.011   \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.994$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:erc_perf_eval_table}
\end{table}

Figure~\ref{fig:pca_rfc_percInconclCases_development} illustrates the determined lower and upper bounds on the 
probabilistic output as a function of the percentages of inconclusive cases in the validation set (development dataset), 
along with the natural cutoff of $0.5$.
The width of the inconclusive interval expands as the percentage of inconclusive cases increases 
and the visual resemblance in shape and slope between the curve a similar distribution of predictions both below and above the cutoff.

The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) 
is demonstrated in Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_development}.
The deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% pca_rfc_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/pca_rfc/86/sigmoid_percInconclCases_pca_rfc_development.png}
  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:pca_rfc_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_pca_rfc_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_development.png}
  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_development}
\end{figure} 


Figure~\ref{fig:bacc_obsInconclCases_pca_rfc_development} shows the balanced accuracy (mean$\pm$SD across random splits) 
on both conclusive and inconclusive cases as a function of the mean PIncObs
in the test set (development dataset).
The balanced accuracy on inconclusive cases is not part of performance analysis and comparison 
due to the emphasis on the balanced accuracy on conclusive cases as the basis for the main metric of this work.

The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs
is depicted with enhanced clarity and precision in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_development}.
The mean of the balanced accuracy rises from approximately 97\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the PCA-RFC baseline method achieves a relative AUC of 98.71\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_pca_rfc_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_pca_rfc_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_pca_rfc_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_development}
  \end{subfigure}

  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_pca_rfc_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

The PCA-RFC baseline method was also evaluated on the independent test datasets PPMI and MPH.
The performance results for the PCA-RFC method on the PPMI test dataset are presented in Figure~\ref{fig:perf_results_rfc_ppmi} 
whereas Figure~\ref{fig:perf_results_rfc_mph} presents the results for the PCA-RFC method on the MPH test dataset.


% ---------------- PPMI ---------------------

The following results were obtained when evaluating the PCA-RFC method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_ppmi} shows the
mean$\pm$SD percentage of inconclusive cases observed in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
The function is consistently above the identity line which implies that the PCA-RFC method 
produces relatively more inconclusive cases for the PPMI dataset  
in comparison to the validation set and thus exhibits lower prediction confidence on the PPMI dataset, 
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is presented 
in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_ppmi}.
The mean of the balanced accuracy rises from approximately 98\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The PCA-RFC baseline method achieves a relative AUC of 99.12\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_pca_rfc_ppmi and bacc_obsInconclCases_concl_pca_rfc_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_ppmi}
  \end{subfigure}
  \caption{Evaluation of the PCA-RFC method on PPMI dataset.}
  \label{fig:perf_results_rfc_ppmi}
\end{figure}



% -------------- MPH -----------------


The evaluation of the PCA-RFC method on the MPH dataset shows the following results.
In Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_mph} 
the mean$\pm$SD percentage of inconclusive cases observed in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (development dataset) is illustrated.
As in the PPMI case, the percentage of inconclusive cases observed in the MPH test dataset
is also above the identity line however the deviation is much stronger.
Therefore the PCA-RFC method produces relatively much more inconclusive cases for the MPH dataset  
in comparison to the validation set.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_mph}.
The mean of the balanced accuracy rises from approximately 90.5\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 94\% 
when there are around 19\% of inconclusive cases in the MPH test set.
As a result, the PCA-RFC baseline method achieves a relative AUC of 92.42\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_pca_rfc_mph and bacc_obsInconclCases_concl_pca_rfc_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_mph}
  \end{subfigure}
  \caption{Evaluation of the PCA-RFC method on MPH dataset.}
  \label{fig:perf_results_rfc_mph}
\end{figure}


\subsection{Experimental Methods Performance}
\label{subsec:exp_methods_perf}

This section presents the performance results for the CNN-based classification approaches sepertatly and compares them 
to the results obtained by the baseline approaches.
First the results for the CNN-MVT method are presented, whereafter the CNN-RLT method is evaluated.
Finally the findings for the CNN-Regression method are showcasted.

\subsubsection{CNN-MVT Method Results}
\label{subsubsec:eval_mvt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset

The quantitative performance results of the CNN-MVT classification on the 
particular subset of the Development dataset are presented in Table~\ref{t1:cnn_mvt_perf_eval_table}.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The CNN-MVT method achieves around 96.4\% in sensitivity, 97.6\% in specificity and a balanced accuracy of 97.0\%, 
with a variance between 1-2\% across random splits, on the test set.
The performance results on the validation set are very similar.
The method achieves a stable AUC-ROC of 0.996$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the CNN-MVT method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.999$\pm$0.003   &  0.970$\pm$0.014    &  0.970$\pm$0.008   \\
      Accuracy          & 0.999$\pm$0.003    &   0.970$\pm$0.014   &  0.970$\pm$0.008   \\
      Sensitivity       &  1.000$\pm$0.000   &   0.963$\pm$0.010   &  0.964$\pm$0.015  \\
      Specificity       &   0.997$\pm$0.006   &   0.976$\pm$0.023  &   0.976$\pm$0.013  \\
      PPV               &  0.997$\pm$0.006   &   0.975$\pm$0.024   &  0.972$\pm$0.018 \\
      NPV               &  1.000$\pm$0.000    &   0.966$\pm$0.010   & 0.968$\pm$0.014  \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.996$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_mvt_perf_eval_table}
\end{table}


In Figure~\ref{fig:baseline_majority_percInconclCases_development} the determined lower and upper bounds on the 
probabilistic sigmoid output are plotted as a function of the percentages of inconclusive cases 
in the validation set (development dataset), along with the natural cutoff $0.5$.
The visual resemblance in shape and slope between the upper and lower bound curves 
indicates a similar distribution of predictions both below and above the cutoff.
The width of the inconclusive interval increases more rapidly as the percentage of inconclusive cases increases 
when compared to the PCA-RFC baseline method.
That implies that the CNN-MVT method produces relatively less inconclusive cases than the PCA-RFC baseline.


The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) 
is illustrated in Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_development}.
As for the baseline cases, the deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% baseline_majority_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_majority/86/sigmoid_percInconclCases_baseline_majority_development.png}
  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:baseline_majority_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_baseline_majority_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_development.png}
  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_development}
\end{figure} 


The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs
in the test set (development dataset) 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_development}.
The mean of the balanced accuracy rises from about 97\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the CNN-MVT method achieves a relative AUC of 98.95\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The achieved relative AUC is approximately 2.5\% higher than that of the SBR baseline method 
and around 0.2\% higher than the PCA-RFC baseline.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_baseline_majority_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_baseline_majority_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_baseline_majority_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_baseline_majority_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

The CNN-MVT method was also evaluated on the independent test datasets PPMI and MPH.
The performance results for the CNN-MVT method on the PPMI test dataset are presented in Figure~\ref{fig:perf_results_mvt_ppmi} 
whereas Figure~\ref{fig:perf_results_mvt_mph} presents the results for the CNN-MVT method on the MPH test dataset.


% ---------------- PPMI ---------------------


The following results were obtained when evaluating the CNN-MVT method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_ppmi} depicts the
mean$\pm$SD percentage of inconclusive cases observed in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
For lower percentages of inconclusive cases in the validation set the corresponding 
percentages of observed inconclusive cases in the PPMI test dataset are similar.
However for higher percentages of inconclusive cases (corresponding to braoder inconclusive intervals) 
in the validation set the method produces relatively more inconclusive cases for the PPMI dataset 
and thus exhibits less confidence.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is illustrated 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_ppmi}.
The mean of the balanced accuracy rises from approximately 98\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The CNN-MVT method achieves a relative AUC of 99.23\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
The achieved relative AUC is approximately 1.7\% higher than that of the SBR baseline method 
and around 0.1\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_majority_ppmi and bacc_obsInconclCases_concl_baseline_majority_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-MVT method on PPMI dataset.}
  \label{fig:perf_results_mvt_ppmi}
\end{figure}


% -------------- MPH -----------------


The evaluation of the CNN-MVT method on the MPH dataset produced the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_mph} presents
the mean$\pm$SD percentage of inconclusive cases observed in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
The mean of the percentage of inconclusive cases observed in the MPH test dataset
is above the identity line 
and increases as the percentage of inconclusive cases in the validation set increases.
The standard deviation also increases over the percentage of inconclusive cases in the validation set.
When compared to the SBR baseline the CNN-MVT method shows a stronger misalignment between 
the percentage of inconclusive cases in validation and test set. 
However compared to the PCA-RFC baseline the CNN-MVT method exhibits better alignment.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is depicted 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_mph}.
The mean of the balanced accuracy increases from approximately 95\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 96\% 
when there are around 20\% of inconclusive cases in the MPH test set.
As a result, the CNN-MVT method achieves a relative AUC of 95.73\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
The achieved relative AUC is approximately 2.3\% higher than that of the SBR baseline method 
and around 3.3\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_majority_mph and bacc_obsInconclCases_concl_baseline_majority_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-MVT method on MPH dataset.}
  \label{fig:perf_results_mvt_mph}
\end{figure}


\subsubsection{CNN-RLT Method Results}
\label{subsubsec:eval_rlt}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset

The quantitative performance results of the CNN-RLT classification on the 
particular subset of the Development dataset are presented in Table~\ref{t1:cnn_rlt_perf_eval_table}.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The CNN-RLT method achieves around 96.1\% in sensitivity, 98.5\% in specificity and a balanced accuracy of 97.3\%, 
with a variance between 0.5-1.5\% across random splits, on the test set.
The performance results on the validation set are similar.
The method achieves a stable AUC-ROC of 0.994$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the CNN-RLT method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.982$\pm$0.003   &  0.967$\pm$0.008    &  0.973$\pm$0.005  \\
      Accuracy          & 0.982$\pm$0.003    &   0.968$\pm$0.008   &  0.973$\pm$0.005  \\
      Sensitivity       &  0.980$\pm$0.008  &   0.951$\pm$0.013  &  0.961$\pm$0.014 \\
      Specificity       &   0.983$\pm$0.008   &   0.984$\pm$0.005  &   0.985$\pm$0.010 \\
      PPV               &  0.983$\pm$0.009   &   0.982$\pm$0.006   &  0.982$\pm$0.012   \\
      NPV               &  0.981$\pm$0.008   &   0.956$\pm$0.012   & 0.966$\pm$0.013  \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.994$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_rlt_perf_eval_table}
\end{table}


Figure~\ref{fig:baseline_random_percInconclCases_development} shows the determined lower and upper bounds on the 
probabilistic sigmoid output as a function of the percentages of inconclusive cases 
in the validation set (development dataset), along with the natural cutoff $0.5$.
The upper bound curve increases and saturates faster than the lower bound curve with a lower variance across 
the random splits.
First this suggests a disparity in the distribution of predictions below and above the cutoff point.
Also the determination of stable lower bounds across the random splits is more difficult
than the determination of stable upper bounds.
When compared to the PCA-RFC baseline method 
the width of the inconclusive interval increases more rapidly as the percentage of inconclusive cases increases.
That implies that the CNN-RLT method tends to produce relatively less inconclusive cases than the PCA-RFC baseline.

The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) 
is depicted in Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_random_development}.
As for the baseline cases, the deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% baseline_random_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_random/86/sigmoid_percInconclCases_baseline_random_development.png}
  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:baseline_random_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_baseline_random_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_development.png}
  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_baseline_random_development}
\end{figure} 


The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs in the test set (development dataset) 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_random_development}.
The mean of the balanced accuracy rises from about 97.5\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the CNN-RLT method achieves a relative AUC of 99.02\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The achieved relative AUC is approximately 2.6\% higher than that of the SBR baseline method 
and around 0.3\% higher than the PCA-RFC baseline.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_baseline_random_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_baseline_random_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_baseline_random_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_baseline_random_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

The CNN-RLT method was also evaluated on the independent test datasets PPMI and MPH.
The performance results for the CNN-RLT method on the PPMI test dataset are presented in Figure~\ref{fig:perf_eval_rlt_ppmi} 
whereas Figure~\ref{fig:perf_eval_rlt_mph} presents the results for the CNN-RLT method on the MPH test dataset.


% ---------------- PPMI ---------------------

The following results were obtained when evaluating the CNN-RLT method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_random_ppmi} shows the
mean$\pm$SD percentage of inconclusive cases observed in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
Here for lower percentages of inconclusive cases in the validation set (less than 6\%) the corresponding 
mean$\pm$SD percentages of observed inconclusive cases in the PPMI test dataset are below the identity line.
However for higher percentages of inconclusive cases in the validation set the mean rises above the identity line
and the standard deviation increases strongly.
That indicates that the method makes relatively less predictions around the cutoff for PPMI dataset cases than 
for the validation set cases.
As the inconclusive interval increases the amount of PPMI predictions within the inconclusive interval varies strongly 
across random splits with a bias towards producing relatively more inconclusive PPMI dataset cases 
than inconclusive validation set cases.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is presented 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_random_ppmi}.
The mean of the balanced accuracy rises from approximately 98.5\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The CNN-RLT method achieves a relative AUC of 99.31\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
The achieved relative AUC is approximately 1.8\% higher than that of the SBR baseline method 
and around 0.2\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_random_ppmi and bacc_obsInconclCases_concl_baseline_random_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_random_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-RLT method on PPMI dataset.}
  \label{fig:perf_eval_rlt_ppmi}
\end{figure}



% -------------- MPH -----------------

The evaluation of the CNN-RLT method on the MPH dataset produced the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_random_mph} illustrates
the mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) (development dataset).
Here the mean of the PIncObs in the MPH test dataset is slightly above the identity line 
and the standard deviation increases over the PIncVal.
Compared to the mean of the PCA-RFC benchmark method, 
the mean of the PIncObs in the MPH test dataset of the CNN-RLT method is better aligned with the PIncVal.
However the standard deviation of the PIncObs in the MPH test dataset across the random splits 
is higher for the CNN-RLT method.
The balanced accuracy on conclusive cases over the mean PIncObs is depicted 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_random_mph}.
The mean of the balanced accuracy slightly increases from approximately 95\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 96\% 
when there are around 20\% of inconclusive cases in the MPH test set.
As a result, the CNN-RLT method achieves a relative AUC of 96.12\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
The achieved relative AUC is approximately 2.7\% higher than that of the SBR baseline method 
and around 3.7\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_random_mph and bacc_obsInconclCases_concl_baseline_random_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_random_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-RLT method on MPH dataset.}
  \label{fig:perf_eval_rlt_mph}
\end{figure}


\subsubsection{CNN-Regression Method Results}
\label{subsubsec:eval_regression}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Development dataset

The quantitative performance results of the CNN-Regression classification on the 
particular subset of the Development dataset are presented in Table~\ref{t1:cnn_regression_perf_eval_table}.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The CNN-Regression method achieves around 96.1\% in sensitivity, 98.5\% in specificity and a balanced accuracy of 97.5\%, 
with a standard deviation between 0.6-1.1\% across random splits, on the test set.
The performance results on the validation set are a balanced accuracy of 97.7\%, a sensitivity of 98.3\% 
and a specificity of 97.2\%.
The method achieves a stable AUC-ROC of 0.998$\pm$0.001.


\begin{table}[ht]
  \caption{Evaluation of the CNN-Regression method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.982+/-0.003   &  0.977+/-0.006    &  0.975+/-0.006 \\
      Accuracy          & 0.980+/-0.003     &   0.977+/-0.007   &  0.976+/-0.006  \\
      Sensitivity       &  1.000+/-0.000   &   0.983+/-0.009   &  0.961+/-0.011 \\
      Specificity       &   0.963+/-0.005  &   0.972+/-0.009 &   0.988+/-0.008 \\
      PPV               &  0.960+/-0.005    &   0.967+/-0.011  &  0.986+/-0.009  \\
      NPV               &  1.000+/-0.000  &   0.985+/-0.008   & 0.967+/-0.010 \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.998+/-0.001}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_regression_perf_eval_table}
\end{table}


Figure~\ref{fig:regression_percInconclCases_development} presents the determined lower and upper bounds on the 
probabilistic sigmoid output as a function of the percentages of inconclusive cases 
in the validation set (PIncVal) of the development dataset, along with the natural cutoff $0.5$.
Similar as for the CNN-RLT method, 
here the upper bound curve increases and saturates slightly faster than the lower bound curve with a lower variance across 
the random splits.
This suggests a slight disparity in the distribution of predictions below and above the cutoff point.
Since both the upper and lower bound functions exhibit a significant standard deviation across the random splits 
the determination of stable lower and upper bounds is difficult.
When compared to the PCA-RFC baseline method 
the width of the inconclusive interval increases more rapidly over the PIncVal.
Thereore the CNN-Regression method also tends to produce relatively less inconclusive cases than the PCA-RFC baseline.

The correspondence between the PIncVal of the development dataset \linebreak 
and the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set of the development dataset 
is depicted in Figure~\ref{fig:obsInconclCases_inconclCasesValid_regression_development}.
As for the baseline cases, the deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).

% regression_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/regression/86/sigmoid_percInconclCases_regression_development.png}
  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:regression_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_regression_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_development.png}
  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_regression_development}
\end{figure} 


The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs in the test set (development dataset) 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_regression_development}.
The mean of the balanced accuracy rises from about 98\% when there is a PIncObs of 1\% in the test set 
to about 99.5\% when there is a PIncObs around 20\% in the test set.
As a result, the CNN-Regression method achieves a relative AUC of 99.23\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The achieved relative AUC is approximately 2.8\% higher than that of the SBR baseline method 
and around 0.5\% higher than the PCA-RFC baseline.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_regression_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_regression_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_regression_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_regression_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_regression_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

The CNN-Regression method was also evaluated on the independent test datasets PPMI and MPH.
The performance results for the CNN-Regression method on the PPMI test dataset are presented in Figure~\ref{fig:perf_regression_ppmi} 
whereas Figure~\ref{fig:perf_regression_mph} presents the results for the CNN-Regression method on the MPH test dataset.


% ---------------- PPMI ---------------------

The following results were obtained when evaluating the CNN-Regression method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_regression_ppmi} illustrates the
mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
Here for lower percentages of inconclusive cases in the validation set (less than 5\%) the corresponding 
mean of PIncObs in the PPMI test dataset is near the identity line.
However for higher percentages of inconclusive cases in the validation set the mean of PIncObs rises above the identity line
and the standard deviation of PIncObs increases strongly.
That indicates that the method produces a similar amount of predictions around the cutoff for PPMI dataset cases and 
for the validation set cases.
As the inconclusive interval increases the amount of predictions for PPMI cases within the inconclusive interval 
varies strongly across random splits and the method tends to produce relatively more inconclusive cases for the 
PPMI dataset when compared to validation set on average.
The balanced accuracy on conclusive cases over the mean PIncObs is presented in Figure~\ref{fig:bacc_obsInconclCases_concl_regression_ppmi}.
The mean of the balanced accuracy rises from approximately 98.5\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The CNN-Regression method achieves a relative AUC of 99.38\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
The achieved relative AUC is approximately 1.9\% higher than that of the SBR baseline method 
and around 0.3\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_regression_ppmi and bacc_obsInconclCases_concl_regression_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_regression_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_regression_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-Regression method on PPMI dataset.}
  \label{fig:perf_regression_ppmi}
\end{figure}



% -------------- MPH -----------------


The evaluation of the CNN-Regression method on the MPH dataset produced the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_regression_mph} demonstrates
the mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) (development dataset).
Here the mean of the PIncObs in the MPH test dataset is above the identity line 
and deviates stronger from the identity line as the PIncVal increases.
Also the standard deviation of the PIncObs increases over the increasing PIncVal.
Compared to the mean of the PCA-RFC benchmark method, 
the mean of the PIncObs in the MPH test dataset of the CNN-Regression method is closer aligned with the PIncVal.
However the standard deviation of the PIncObs in the MPH test dataset across the random splits 
is much higher for the CNN-Regression method.
The balanced accuracy on conclusive cases over the mean PIncObs 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_regression_mph}.
The mean of the balanced accuracy slightly increases from approximately 95\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 96.5\% 
when there are around 20\% of inconclusive cases in the MPH test set.
As a result, the CNN-Regression method achieves a relative AUC of 96.24\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
The achieved relative AUC is approximately 2.8\% higher than that of the SBR baseline method 
and around 3.8\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_regression_mph and bacc_obsInconclCases_concl_regression_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_regression_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_regression_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-Regression method on MPH dataset.}
  \label{fig:perf_regression_mph}
\end{figure}


\subsection{Comparative Analysis}
\label{subsec:compar_anal}


\subsubsection{Comparison of Performance on Test set of Development dataset}
\label{subsubsec:perf_comp_dev}


% Method Comparison of obsInconclCases_inconclCasesValid - Development test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_development.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_development.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_development.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_development.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_development.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on test set of development data. Inconclusive interval matching.}
  \label{fig:test_interval_match_dev}
\end{figure}

% Method Comparison of bacc-obsInconclCases-concl - Development test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_development.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_development.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_development.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_development.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_development.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on test set of development data.}
  \label{fig:test_dev}
\end{figure}



\subsubsection{Comparison of Performance on Independent datasets}
\label{subsubsec:perf_comp_indep}


% ------ PPMI --------


% Method Comparison of obsInconclCases_inconclCasesValid - PPMI
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_ppmi.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_ppmi.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_ppmi.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_ppmi.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_ppmi.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on PPMI dataset. Inconclusive interval matching.}
  \label{fig:test_interval_match_ppmi}
\end{figure}


% Method Comparison of bacc_obsInconclCases_concl - PPMI test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_ppmi.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_ppmi.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_ppmi.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_ppmi.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_ppmi.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on PPMI dataset.}
  \label{fig:test_ppmi}
\end{figure}


% ------ MPH --------

% Method Comparison of obsInconclCases_inconclCasesValid - MPH
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_mph.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_mph.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_mph.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_mph.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_mph.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on MPH dataset. Inconclusive interval matching.}
  \label{fig:test_interval_match_mph}
\end{figure}


% Method Comparison of bacc_obsInconclCases_concl - MPH test set
\begin{figure}[t]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_mph.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_mph.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_mph.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_mph.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_mph.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on MPH dataset.}
  \label{fig:test_mph}
\end{figure}



% AUC bAcc comparison of different methods and dataset
\begin{figure}[h]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/auc_main_comparison.png}
  \caption{Comparison of AUC achieved by each method on different test data. 
  The AUC was calculated for the mean balanced accuracy over the percentage of inconclusive cases 
  in the considered test set.} 
  \label{fig:auc_comparison_methods_data}
\end{figure} 