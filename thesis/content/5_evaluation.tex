\section{Evaluation}
\label{sec:evaluation}

The preceding chapters have detailed the research methodology, data collection and sources, and the application of classification techniques 
to address the research questions posed in this study. 

This chapter embarks on the evaluation of the research results, focusing on the performance and effectiveness of the methods employed, 
and the attainment of the research objectives.

The structure of this chapter has been designed to systematically lead readers through the assessment process. 
The chapter commences with the examination of the performance results obtained for the baseline methods.
The core of this chapter subsequently unveils the results 
for the experimental methods evaluated using various test datasets and compared to the baseline performance.
These findings are presented using performance summary tables for statistical measures and graphical representations.
The chapter culminates with a comparative analysis, which seeks to assess and contrast the effectiveness and 
limitations of the research methods employed.

\subsection{Baseline Performance}
\label{subsec:baseline_performance}

In this section, the performance of the SBR method, a widely recognized technique in the field, 
is thoroughly evaluated. 
Furthermore the outcomes for the multivariate PCA-RFC method are also provided as additional baseline.
The objective of this evaluation is twofold: to comprehend the inherent capabilities of the baseline methods, SBR and
PCA-RFC, and to establish a clear point of reference for the CNN-based methodologies.

\subsubsection{SBR Method Results}
\label{subsubsec:eval_sbr}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Test set of development dataset}

% Evaluation on Development dataset
\subparagraph{Binary classification performance}

Table~\ref{t1:sbr_perf_eval_table} presents the quantitative performance 
(Balanced accuracy, accuracy, sensitivity, specificity, PPV, NPV and AUC-ROC) of the SBR-based classification on the 
particular subset of the Development dataset.
In the evaluation process, the optimal SBR cutoff value of 0.703 (with a variation of $\pm$0.009 across random splits) 
was employed.
The SBR method consistently achieves around 93\% in balanced accuracy, accuracy, sensitivity, specificity, PPV and NPV 
on the training set, with a variance around 0.5\% across random splits.
The performance on validation and test set is also around 93\% with respect to all the metrics
with a slightly higher variance across random splits (0.5-2\%) compared to training set.
The comparable sensitivity and specificity imply a well-balanced SBR model which 
identifies both positive and negative cases similarly well.
The SBR model achieves a stable AUC-ROC of 0.983$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the SBR method on Development dataset (SBR cutoff mean$\pm$SD: 0.703$\pm$0.009).}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.936$\pm$0.003   &   0.929$\pm$0.008   &  0.935$\pm$0.007     \\
      Accuracy          & 0.936$\pm$0.003   &   0.930$\pm$0.008   &  0.935$\pm$0.007     \\
      Sensitivity       &  0.934$\pm$0.006  &   0.924$\pm$0.005   &  0.930$\pm$0.014     \\
      Specificity       & 0.937$\pm$0.003   &   0.935$\pm$0.015   &  0.939$\pm$0.012     \\
      PPV               &  0.933$\pm$0.005  &   0.929$\pm$0.014   &  0.930$\pm$0.015     \\
      NPV               &  0.938$\pm$0.005  &   0.930$\pm$0.004   &  0.938$\pm$0.018     \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.983$\pm$0.002 }  \\
      \hline
  \end{tabular}
 \label{t1:sbr_perf_eval_table}
\end{table}

\subparagraph{Determined inconclusive intervals}

Figure~\ref{fig:sbr_percInconclCases_development} illustrates the determined lower and upper bounds on the SBR 
as a function of the percentages of inconclusive cases in the validation set (development dataset), 
along with the mean$\pm$SD of the optimal cutoff.
Corroborating the intuitive expectation, the width of the inconclusive interval expands 
as the percentage of inconclusive cases increases.
The close resemblance in slopes between the upper and lower bound functions 
indicates a nearly identical distribution of predictions both below and above the cutoff.

\subparagraph{Transferability of inconclusive intervals}

In Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_development} the correspondence between 
the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) is demonstrated.
The plot illustrates that the deviation of the mean PIncObs in the test set from the 
identity line is negligibly small.
This can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting) which results in a similar distribution of SBR model predictions.


% sbr_percInconclCases_development
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{content/figures/evaluations/sbr/86/sbr_percInconclCases_development.png}
    \caption{Evaluation of the SBR method on Test Set of Development dataset. 
    Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
    \label{fig:sbr_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_sbr_development
\begin{figure}[ht]
    \centering
    \includegraphics[width=1.0\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_development.png}
    \caption{Evaluation of the SBR method on Test Set of Development dataset.
    Observed percentage of inconclusive cases in the test set 
    for a given set of percentages of inconclusive cases in the validation set.
    Each of the percentages of inconclusive cases in the validation set is associated 
    with an inconclusive range (determined in the validation set).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_development}
\end{figure} 

\subparagraph{AUC for balanced accuracy over PIncObs}

Figure~\ref{fig:bacc_obsInconclCases_sbr_development} shows the balanced accuracy (mean$\pm$SD across random splits) 
on both conclusive and inconclusive cases as a function of the mean PIncObs
in the test set (development dataset).
The balanced accuracy on inconclusive cases is not part of further performance analysis and comparison 
due to the emphasis on the balanced accuracy on conclusive cases as the basis for the main metric of this work.
The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs
is depicted with enhanced clarity and precision in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_development}.
The mean of the balanced accuracy rises from approximately 94\% 
when there are around 1\% of inconclusive cases in the test set to about 98\% 
when there are around 20\% of inconclusive cases in the test set.
The SBR baseline method attains a relative AUC of 96.38\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.

% bacc_obsInconclCases_sbr_development_full
\begin{figure}[ht]
    \begin{subfigure}{0.9\textwidth}
      \centering
      \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_sbr_development.png}
      \subcaption{}
      \label{fig:bacc_obsInconclCases_sbr_development}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.9\textwidth}
      \centering
      \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_development.png}
      \subcaption{}
      \label{fig:bacc_obsInconclCases_concl_sbr_development}
    \end{subfigure}

    \caption{Evaluation of the SBR method on Test Set of Development dataset.
    Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
    (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
    Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
    \label{fig:bacc_obsInconclCases_sbr_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

% ---------------- PPMI ---------------------

\paragraph{PPMI dataset}

The results obtained from evaluating the SBR method on the PPMI dataset 
are depicted in Figure~\ref{fig:perf_results_sbr_ppmi}.
The mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset) 
is consistently below the identity line, 
which can be seen in Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_ppmi}.
That implies that, on average, the supposed prediction certainty on PPMI dataset is higher than on validation set (development dataset),
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean PIncObs is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_ppmi}.
The mean of the balanced accuracy rises from approximately 96\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The SBR baseline method achieves a relative AUC of 97.51\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_sbr_ppmi and bacc_obsInconclCases_concl_sbr_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_sbr_ppmi}
  \end{subfigure}
  \caption{Evaluation of the SBR method on PPMI dataset.}
  \label{fig:perf_results_sbr_ppmi}
\end{figure}



% -------------- MPH -----------------

\paragraph{MPH dataset}

The evaluation of the SBR method on the MPH dataset is shown in Figure~\ref{fig:perf_results_sbr_mph}.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_sbr_mph} demonstrates 
the mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
Similar as in case of the PPMI dataset, here the PIncObs in the MPH test dataset
is also consistently below the identity line 
and thus the supposed prediction certainty on MPH dataset is higher than on validation set.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_sbr_mph}.
The mean of the balanced accuracy rises from approximately 91.5\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 95\% 
when there are around 20\% of inconclusive cases in the MPH test set.
The SBR baseline method achieves a relative AUC of 93.46\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_sbr_mph and bacc_obsInconclCases_concl_sbr_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/obsInconclCases_inconclCasesValid_sbr_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_sbr_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/sbr/86/bacc_obsInconclCases_concl_sbr_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_sbr_mph}
  \end{subfigure}
  \caption{Evaluation of the SBR method on MPH dataset.}
  \label{fig:perf_results_sbr_mph}
\end{figure}

% Write summary of performance on dev test, ppmi and mph and compare


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{PCA-RFC Method Results}
\label{subsubsec:eval_rfc}


\paragraph{Test set of development dataset}


\subparagraph{Binary classification performance}

% Evaluation on Development dataset

Table~\ref{t1:erc_perf_eval_table} presents the quantitative performance 
(Balanced accuracy, accuracy, sensitivity, specificity, PPV, NPV and AUC-ROC) of the PCA-RFC classification on the 
particular subset of the Development dataset.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The PCA-RFC method achieves around 96\% in balanced accuracy, accuracy, sensitivity, specificity, PPV and NPV 
on the validation and test set, with a variance around 1\% across random splits.
The SBR model achieves a stable AUC-ROC of 0.994$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the PCA-RFC method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 1.000$\pm$0.000   &   0.963$\pm$0.010    &  0.966$\pm$0.006   \\
      Accuracy          & 1.000$\pm$0.000    &   0.963$\pm$0.010  &  0.966$\pm$0.006    \\
      Sensitivity       &  1.000$\pm$0.000   &   0.957$\pm$0.012   &  0.962$\pm$0.010   \\
      Specificity       & 1.000$\pm$0.000    &   0.969$\pm$0.011  &  0.969$\pm$0.009   \\
      PPV               &  1.000$\pm$0.000   &   0.966$\pm$0.012   &  0.965$\pm$0.010   \\
      NPV               &  1.000$\pm$0.000   &   0.961$\pm$0.012  &  0.966$\pm$0.011   \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.994$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:erc_perf_eval_table}
\end{table}


\subparagraph{Determined inconclusive intervals}

Figure~\ref{fig:pca_rfc_percInconclCases_development} illustrates the determined lower and upper bounds on the 
probabilistic output as a function of the percentages of inconclusive cases in the validation set (development dataset), 
along with the natural cutoff of $0.5$.
The width of the inconclusive interval expands as the percentage of inconclusive cases increases 
and the visual resemblance in shape and slope between the curve a similar distribution of predictions both below and above the cutoff.

\subparagraph{Transferability of inconclusive intervals}

The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) 
is demonstrated in Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_development}.
The deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% pca_rfc_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/pca_rfc/86/sigmoid_percInconclCases_pca_rfc_development.png}
  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:pca_rfc_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_pca_rfc_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_development.png}
  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_development}
\end{figure} 


\subparagraph{AUC for balanced accuracy over PIncObs}

Figure~\ref{fig:bacc_obsInconclCases_pca_rfc_development} shows the balanced accuracy (mean$\pm$SD across random splits) 
on both conclusive and inconclusive cases as a function of the mean PIncObs
in the test set (development dataset).
The balanced accuracy on inconclusive cases is not part of performance analysis and comparison 
due to the emphasis on the balanced accuracy on conclusive cases as the basis for the main metric of this work.
The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs
is depicted with enhanced clarity and precision in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_development}.
The mean of the balanced accuracy rises from approximately 97\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the PCA-RFC baseline method achieves a relative AUC of 98.71\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_pca_rfc_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_pca_rfc_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_pca_rfc_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_development}
  \end{subfigure}

  \caption{Evaluation of the PCA-RFC method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_pca_rfc_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

% ---------------- PPMI ---------------------

\paragraph{PPMI dataset}

The following results were obtained when evaluating the PCA-RFC method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_ppmi} shows the
mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (development dataset).
The function is consistently above the identity line.
Therefore, on average, the supposed prediction certainty of the PCA-RFC method on PPMI dataset is lower than on validation set,
regardless of the prediction accuracy.
The balanced accuracy on conclusive cases over the mean PIncObs is presented 
in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_ppmi}.
The mean of the balanced accuracy rises from approximately 98\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The PCA-RFC baseline method achieves a relative AUC of 99.12\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_pca_rfc_ppmi and bacc_obsInconclCases_concl_pca_rfc_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_ppmi}
  \end{subfigure}
  \caption{Evaluation of the PCA-RFC method on PPMI dataset.}
  \label{fig:perf_results_rfc_ppmi}
\end{figure}



% -------------- MPH -----------------

\paragraph{MPH dataset}

The evaluation of the PCA-RFC method on the MPH dataset shows the following results.
In Figure~\ref{fig:obsInconclCases_inconclCasesValid_pca_rfc_mph} 
the mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) is illustrated.
Here the mean of PIncObs in the MPH test dataset
is also consistently above the identity line and its deviation from the identity line increases over PIncVal.
Therefore the supposed prediction certainty on MPH dataset is lower than on validation set (development data).
The balanced accuracy on conclusive cases over the mean PIncObs is shown 
in Figure~\ref{fig:bacc_obsInconclCases_concl_pca_rfc_mph}.
The mean of the balanced accuracy rises from approximately 90.5\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 94\% 
when there are around 19\% of inconclusive cases in the MPH test set.
As a result, the PCA-RFC baseline method achieves a relative AUC of 92.42\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_pca_rfc_mph and bacc_obsInconclCases_concl_pca_rfc_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/obsInconclCases_inconclCasesValid_pca_rfc_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_pca_rfc_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/pca_rfc/86/bacc_obsInconclCases_concl_pca_rfc_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_pca_rfc_mph}
  \end{subfigure}
  \caption{Evaluation of the PCA-RFC method on MPH dataset.}
  \label{fig:perf_results_rfc_mph}
\end{figure}


\subsection{Experimental Methods Performance}
\label{subsec:exp_methods_perf}

This section presents the performance results for the CNN-based classification approaches separately and compares them 
to the results obtained by the baseline approaches.
First the results for the CNN-MVT method are presented, whereafter the CNN-RLT method is evaluated.
Finally the findings for the CNN-Regression method are showcased.

\subsubsection{CNN-MVT Method Results}
\label{subsubsec:eval_mvt}

% Evaluation on Development dataset

\paragraph{Test set of development dataset}


\subparagraph{Binary classification performance}

The quantitative performance results of the CNN-MVT classification on the 
particular subset of the Development dataset are presented in Table~\ref{t1:cnn_mvt_perf_eval_table}.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The CNN-MVT method achieves around 96.4\% in sensitivity, 97.6\% in specificity and a balanced accuracy of 97.0\%, 
with a variance between 1-2\% across random splits, on the test set.
The performance results on the validation set are very similar.
The method achieves a stable AUC-ROC of 0.996$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the CNN-MVT method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.999$\pm$0.003   &  0.970$\pm$0.014    &  0.970$\pm$0.008   \\
      Accuracy          & 0.999$\pm$0.003    &   0.970$\pm$0.014   &  0.970$\pm$0.008   \\
      Sensitivity       &  1.000$\pm$0.000   &   0.963$\pm$0.010   &  0.964$\pm$0.015  \\
      Specificity       &   0.997$\pm$0.006   &   0.976$\pm$0.023  &   0.976$\pm$0.013  \\
      PPV               &  0.997$\pm$0.006   &   0.975$\pm$0.024   &  0.972$\pm$0.018 \\
      NPV               &  1.000$\pm$0.000    &   0.966$\pm$0.010   & 0.968$\pm$0.014  \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.996$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_mvt_perf_eval_table}
\end{table}

\subparagraph{Determined inconclusive intervals}

In Figure~\ref{fig:baseline_majority_percInconclCases_development} the determined lower and upper bounds on the 
probabilistic sigmoid output are plotted as a function of the percentages of inconclusive cases 
in the validation set (development dataset), along with the natural cutoff $0.5$.
The visual resemblance in shape and slope between the upper and lower bound curves 
indicates a similar distribution of predictions both below and above the cutoff.
The width of the inconclusive interval increases more rapidly as the percentage of inconclusive cases increases 
when compared to the PCA-RFC baseline method.
That implies that the CNN-MVT method produces relatively less inconclusive cases than the PCA-RFC baseline.


\subparagraph{Transferability of inconclusive intervals}

The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) 
is illustrated in Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_development}.
As for the baseline cases, the deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% baseline_majority_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_majority/86/sigmoid_percInconclCases_baseline_majority_development.png}
  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:baseline_majority_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_baseline_majority_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_development.png}
  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_development}
\end{figure} 


\subparagraph{AUC for balanced accuracy over PIncObs}

The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs
in the test set (development dataset) 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_development}.
The mean of the balanced accuracy rises from about 97\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the CNN-MVT method achieves a relative AUC of 98.95\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The achieved relative AUC is approximately 2.5\% higher than that of the SBR baseline method 
and around 0.2\% higher than the PCA-RFC baseline.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_baseline_majority_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_baseline_majority_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_baseline_majority_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-MVT method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_baseline_majority_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

% ---------------- PPMI ---------------------

\paragraph{PPMI dataset}

The following results were obtained when evaluating the CNN-MVT method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_ppmi} depicts the
mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) of development dataset.
For lower PIncVal the corresponding PIncObs in the PPMI test dataset are similar.
However as PIncVal increases (corresponding to increasing inconclusive intervals) 
the supposed prediction certainty on PPMI dataset decreases when compared to the certainty on validation set, on average.
The balanced accuracy on conclusive cases over the mean PIncObs is illustrated 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_ppmi}.
The mean of the balanced accuracy rises from approximately 98\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The CNN-MVT method achieves a relative AUC of 99.23\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
The achieved relative AUC is approximately 1.7\% higher than that of the SBR baseline method 
and around 0.1\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_majority_ppmi and bacc_obsInconclCases_concl_baseline_majority_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-MVT method on PPMI dataset.}
  \label{fig:perf_results_mvt_ppmi}
\end{figure}


% -------------- MPH -----------------

\paragraph{MPH dataset}

The evaluation of the CNN-MVT method on the MPH dataset produced the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_majority_mph} presents
the mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) of development dataset.
The mean of PIncObs in the MPH test dataset is consisently above the identity line 
and the deviation from the identity line increases over PIncVal.
The standard deviation of PIncObs also increases over PIncVal.
When compared to the mean PIncObs of the SBR baseline the mean PIncObs of the CNN-MVT method is higher 
which indicates that CNN-MVT is supposedly less certain about the MPH set predictions than the SBR method.
Also the PIncObs of the CNN-MVT has a much higher standard deviation compared to the PIncObs of the SBR method.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is depicted 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_majority_mph}.
The mean of the balanced accuracy increases from approximately 95\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 96\% 
when there are around 20\% of inconclusive cases in the MPH test set.
As a result, the CNN-MVT method achieves a relative AUC of 95.73\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
The achieved relative AUC is approximately 2.3\% higher than that of the SBR baseline method 
and around 3.3\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_majority_mph and bacc_obsInconclCases_concl_baseline_majority_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/obsInconclCases_inconclCasesValid_baseline_majority_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_majority_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_majority/86/bacc_obsInconclCases_concl_baseline_majority_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_majority_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-MVT method on MPH dataset.}
  \label{fig:perf_results_mvt_mph}
\end{figure}


\subsubsection{CNN-RLT Method Results}
\label{subsubsec:eval_rlt}

% Evaluation on Development dataset

\paragraph{Test set of development dataset}


\subparagraph{Binary classification performance}

The quantitative performance results of the CNN-RLT classification on the 
particular subset of the Development dataset are presented in Table~\ref{t1:cnn_rlt_perf_eval_table}.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The CNN-RLT method achieves around 96.1\% in sensitivity, 98.5\% in specificity and a balanced accuracy of 97.3\%, 
with a variance between 0.5-1.5\% across random splits, on the test set.
The performance results on the validation set are similar.
The method achieves a stable AUC-ROC of 0.994$\pm$0.002.


\begin{table}[ht]
  \caption{Evaluation of the CNN-RLT method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.982$\pm$0.003   &  0.967$\pm$0.008    &  0.973$\pm$0.005  \\
      Accuracy          & 0.982$\pm$0.003    &   0.968$\pm$0.008   &  0.973$\pm$0.005  \\
      Sensitivity       &  0.980$\pm$0.008  &   0.951$\pm$0.013  &  0.961$\pm$0.014 \\
      Specificity       &   0.983$\pm$0.008   &   0.984$\pm$0.005  &   0.985$\pm$0.010 \\
      PPV               &  0.983$\pm$0.009   &   0.982$\pm$0.006   &  0.982$\pm$0.012   \\
      NPV               &  0.981$\pm$0.008   &   0.956$\pm$0.012   & 0.966$\pm$0.013  \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.994$\pm$0.002}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_rlt_perf_eval_table}
\end{table}


\subparagraph{Determined inconclusive intervals}

Figure~\ref{fig:baseline_random_percInconclCases_development} shows the determined lower and upper bounds on the 
probabilistic sigmoid output as a function of the percentages of inconclusive cases 
in the validation set (development dataset), along with the natural cutoff $0.5$.
The upper bound curve increases and saturates faster than the lower bound curve with a lower variance across 
the random splits.
First this suggests a disparity in the distribution of predictions below and above the cutoff point.
Also the determination of stable lower bounds across the random splits is more difficult
than the determination of stable upper bounds.
When compared to the PCA-RFC baseline method 
the width of the inconclusive interval increases more rapidly as the percentage of inconclusive cases increases.
That implies that the CNN-RLT method tends to produce relatively less inconclusive cases than the PCA-RFC baseline.

\subparagraph{Transferability of inconclusive intervals}

The correspondence between the percentage of inconclusive cases in the validation set (development dataset) and 
the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set (development dataset) 
is depicted in Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_random_development}.
As for the baseline cases, the deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).


% baseline_random_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_random/86/sigmoid_percInconclCases_baseline_random_development.png}
  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:baseline_random_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_baseline_random_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_development.png}
  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_baseline_random_development}
\end{figure} 


\subparagraph{AUC for balanced accuracy over PIncObs}

The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs in the test set (development dataset) 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_random_development}.
The mean of the balanced accuracy rises from about 97.5\% 
when there are around 1\% of inconclusive cases in the test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the test set.
As a result, the CNN-RLT method achieves a relative AUC of 99.02\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The achieved relative AUC is approximately 2.6\% higher than that of the SBR baseline method 
and around 0.3\% higher than the PCA-RFC baseline.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_baseline_random_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_baseline_random_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_baseline_random_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-RLT method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_baseline_random_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets


% ---------------- PPMI ---------------------

\paragraph{PPMI dataset}

The following results were obtained when evaluating the CNN-RLT method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_random_ppmi} shows the
mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) of the development dataset.

Here the mean PIncObs in the PPMI test dataset deviates only slightly from the identity line.
For PIncVal less than 6\% the mean PIncObs is slightly below the identity line.
Subsequently the mean PIncObs rises slightly above the identity line with an increasing standard deviation of PIncObs.
The balanced accuracy on conclusive cases over the mean percentage of observed inconclusive cases (PIncObs) is presented 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_random_ppmi}.
The mean of the balanced accuracy rises from approximately 98.5\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The CNN-RLT method achieves a relative AUC of 99.31\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
The achieved relative AUC is approximately 1.8\% higher than that of the SBR baseline method 
and around 0.2\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_random_ppmi and bacc_obsInconclCases_concl_baseline_random_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_random_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-RLT method on PPMI dataset.}
  \label{fig:perf_eval_rlt_ppmi}
\end{figure}



% -------------- MPH -----------------

\paragraph{MPH dataset}

The evaluation of the CNN-RLT method on the MPH dataset produced the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_baseline_random_mph} illustrates
the mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) (development dataset).
Here the mean of the PIncObs in the MPH test dataset is slightly above the identity line 
and the standard deviation increases over the PIncVal.
The balanced accuracy on conclusive cases over the mean PIncObs is depicted 
in Figure~\ref{fig:bacc_obsInconclCases_concl_baseline_random_mph}.
The mean of the balanced accuracy slightly increases from approximately 95\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 96\% 
when there are around 20\% of inconclusive cases in the MPH test set.
As a result, the CNN-RLT method achieves a relative AUC of 96.12\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
The achieved relative AUC is approximately 2.7\% higher than that of the SBR baseline method 
and around 3.7\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_baseline_random_mph and bacc_obsInconclCases_concl_baseline_random_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/obsInconclCases_inconclCasesValid_baseline_random_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_baseline_random_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/baseline_random/86/bacc_obsInconclCases_concl_baseline_random_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_baseline_random_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-RLT method on MPH dataset.}
  \label{fig:perf_eval_rlt_mph}
\end{figure}


\subsubsection{CNN-Regression Method Results}
\label{subsubsec:eval_regression}


% Evaluation on Development dataset
\paragraph{Test set of development dataset}


\subparagraph{Binary classification performance}

The quantitative performance results of the CNN-Regression classification on the 
particular subset of the Development dataset are presented in Table~\ref{t1:cnn_regression_perf_eval_table}.
In the evaluation process, the natural sigmoid cutoff value of $0.5$ was employed.
The CNN-Regression method achieves around 96.1\% in sensitivity, 98.5\% in specificity and a balanced accuracy of 97.5\%, 
with a standard deviation between 0.6-1.1\% across random splits, on the test set.
The performance results on the validation set are a balanced accuracy of 97.7\%, a sensitivity of 98.3\% 
and a specificity of 97.2\%.
The method achieves a stable AUC-ROC of 0.998$\pm$0.001.


\begin{table}[ht]
  \caption{Evaluation of the CNN-Regression method on Development dataset. 
  For evaluation, the natural sigmoid cutoff $0.5$ was used.}
  \centering
  \begin{tabular}{llll}
      \hline
                        & train set         & validation set      & test set             \\
      \hline
      Balanced Accuracy & 0.982+/-0.003   &  0.977+/-0.006    &  0.975+/-0.006 \\
      Accuracy          & 0.980+/-0.003     &   0.977+/-0.007   &  0.976+/-0.006  \\
      Sensitivity       &  1.000+/-0.000   &   0.983+/-0.009   &  0.961+/-0.011 \\
      Specificity       &   0.963+/-0.005  &   0.972+/-0.009 &   0.988+/-0.008 \\
      PPV               &  0.960+/-0.005    &   0.967+/-0.011  &  0.986+/-0.009  \\
      NPV               &  1.000+/-0.000  &   0.985+/-0.008   & 0.967+/-0.010 \\
      \hline
      AUC-ROC          &  \multicolumn{3}{c}{0.998+/-0.001}  \\
      \hline
  \end{tabular}
 \label{t1:cnn_regression_perf_eval_table}
\end{table}


\subparagraph{Determined inconclusive intervals}

Figure~\ref{fig:regression_percInconclCases_development} presents the determined lower and upper bounds on the 
probabilistic sigmoid output as a function of the percentages of inconclusive cases 
in the validation set (PIncVal) of the development dataset, along with the natural cutoff $0.5$.
Similar to the CNN-RLT method, 
here the upper bound curve increases and saturates slightly faster than the lower bound curve with a lower variance across 
the random splits.
This suggests a slight disparity in the distribution of predictions below and above the cutoff point.
Since both the upper and lower bound functions exhibit a significant standard deviation across the random splits 
the determination of stable lower and upper bounds is difficult.
When compared to the PCA-RFC baseline method 
the width of the inconclusive interval increases more rapidly over the PIncVal.
Therefore the CNN-Regression method also tends to produce relatively less inconclusive cases than the PCA-RFC baseline.


\subparagraph{Transferability of inconclusive intervals}

The correspondence between the PIncVal of the development dataset 
and the mean$\pm$SD percentage of observed inconclusive cases (PIncObs) in the test set of the development dataset 
is depicted in Figure~\ref{fig:obsInconclCases_inconclCasesValid_regression_development}.
As for the baseline cases, the deviation of the mean PIncObs in the test set from the 
identity line is small which can be attributed to the nearly identical distribution of data in both the test and validation sets 
(due to random splitting).

% regression_percInconclCases_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/regression/86/sigmoid_percInconclCases_regression_development.png}
  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset. 
  Determined upper and lower bounds of the inconclusive interval as a function of the percentage of inconclusive cases.} 
  \label{fig:regression_percInconclCases_development}
\end{figure}


% obsInconclCases_inconclCasesValid_regression_development
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_development.png}
  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset.
  Observed percentage of inconclusive cases in the test set 
  for a given set of percentages of inconclusive cases in the validation set.
  Each of the percentages of inconclusive cases in the validation set is associated 
  with an inconclusive range (determined in the validation set).} 
  \label{fig:obsInconclCases_inconclCasesValid_regression_development}
\end{figure} 


\subparagraph{AUC for balanced accuracy over PIncObs}

The balanced accuracy (mean$\pm$SD) on conclusive cases over the mean PIncObs in the test set (development dataset) 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_regression_development}.
The mean of the balanced accuracy rises from about 98\% when there is a PIncObs of 1\% in the test set 
to about 99.5\% when there is a PIncObs around 20\% in the test set.
As a result, the CNN-Regression method achieves a relative AUC of 99.23\% for the mean balanced accuracy on conclusive cases
over the mean PIncObs in the test set of the development dataset.
The achieved relative AUC is approximately 2.8\% higher than that of the SBR baseline method 
and around 0.5\% higher than the PCA-RFC baseline.
The area under the mean of the balanced accuracy is highlighted for better illustration.


% bacc_obsInconclCases_regression_development_full
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_regression_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_regression_development}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_development.png}
    \subcaption{}
    \label{fig:bacc_obsInconclCases_concl_regression_development}
  \end{subfigure}

  \caption{Evaluation of the CNN-Regression method on Test Set of Development dataset.
  Balanced accuracy for a given mean percentage of observed inconclusive cases in the test set on 
  (a) both conclusive and inconclusive cases and (b) only conclusive cases. 
  Each of the mean percentages of observed inconclusive cases is associated with an inconclusive range (determined in the validation set). }
  \label{fig:bacc_obsInconclCases_regression_development_full}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Evaluation on Independent datasets

% ---------------- PPMI ---------------------

\paragraph{PPMI dataset}

The following results were obtained when evaluating the CNN-Regression method on the PPMI dataset.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_regression_ppmi} illustrates the
mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the PPMI test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) of the development dataset.
Here for lower PIncVal values (less than 5\%) the corresponding mean PIncObs 
in the PPMI test dataset is near the identity line.
However for higher PIncVAl values the mean of PIncObs increasingly rises above the identity line
and the standard deviation of PIncObs increases strongly.
The balanced accuracy on conclusive cases over the mean PIncObs is presented in Figure~\ref{fig:bacc_obsInconclCases_concl_regression_ppmi}.
The mean of the balanced accuracy rises from approximately 98.5\% 
when there are around 1\% of inconclusive cases in the PPMI test set to about 99.5\% 
when there are around 20\% of inconclusive cases in the PPMI test set.
The CNN-Regression method achieves a relative AUC of 99.38\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the PPMI test dataset.
The achieved relative AUC is approximately 1.9\% higher than that of the SBR baseline method 
and around 0.3\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_regression_ppmi and bacc_obsInconclCases_concl_regression_ppmi
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_ppmi.png}
    \subcaption{Observed percentage of inconclusive cases in the PPMI dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_regression_ppmi}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_ppmi.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the PPMI dataset.}
    \label{fig:bacc_obsInconclCases_concl_regression_ppmi}
  \end{subfigure}
  \caption{Evaluation of the CNN-Regression method on PPMI dataset.}
  \label{fig:perf_regression_ppmi}
\end{figure}



% -------------- MPH -----------------

\paragraph{MPH dataset}

The evaluation of the CNN-Regression method on the MPH dataset produced the following results.
Figure~\ref{fig:obsInconclCases_inconclCasesValid_regression_mph} demonstrates
the mean$\pm$SD percentage of inconclusive cases observed (PIncObs) in the MPH test dataset 
over the percentage of inconclusive cases in the validation set (PIncVal) (development dataset).
Here the mean of the PIncObs in the MPH test dataset is above the identity line 
and deviates stronger from the identity line as the PIncVal increases.
Also the standard deviation of the PIncObs is high and increases over the increasing PIncVal.
The balanced accuracy on conclusive cases over the mean PIncObs 
is depicted in Figure~\ref{fig:bacc_obsInconclCases_concl_regression_mph}.
The mean of the balanced accuracy slightly increases from approximately 95\% 
when there are around 1\% of inconclusive cases in the MPH test set to about 96.5\% 
when there are around 20\% of inconclusive cases in the MPH test set.
As a result, the CNN-Regression method achieves a relative AUC of 96.24\% for the mean balanced accuracy on conclusive cases 
over the mean PIncObs in the MPH test dataset.
The achieved relative AUC is approximately 2.8\% higher than that of the SBR baseline method 
and around 3.8\% higher than the PCA-RFC baseline.
For better illustration the area under the mean of the balanced accuracy is highlighted.


% obsInconclCases_inconclCasesValid_regression_mph and bacc_obsInconclCases_concl_regression_mph
\begin{figure}[ht]
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/obsInconclCases_inconclCasesValid_regression_mph.png}
    \subcaption{Observed percentage of inconclusive cases in the MPH dataset 
    for a given set of percentages of inconclusive cases in the validation set (Development dataset).} 
    \label{fig:obsInconclCases_inconclCasesValid_regression_mph}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.9\textwidth}
    \centering
    \includegraphics[width=0.9\textwidth]{content/figures/evaluations/regression/86/bacc_obsInconclCases_concl_regression_mph.png}
    \subcaption{Balanced accuracy on conclusive cases for a given mean percentage of inconclusive cases observed 
    in the MPH dataset.}
    \label{fig:bacc_obsInconclCases_concl_regression_mph}
  \end{subfigure}
  \caption{Evaluation of the CNN-Regression method on MPH dataset.}
  \label{fig:perf_regression_mph}
\end{figure}


\subsection{Comparative Performance Analysis}
\label{subsec:compar_anal}

In this section, a summary comparison of the performance between the baseline and experimental methods is presented.
The comparison focuses on the primary metric of this work, 
which is the AUC of balanced accuracy on conclusive cases across varying percentages of observed inconclusive cases. 
%on two aspects: transferability of inconclusive intervals (in both validation and test sets) 
To support the analysis visually one comparison figure is used for each aspect tested on a specific dataset.
The comparison is carried out for the test set of the development data, 
the PPMI dataset and the MPH dataset, respectively.

\subsubsection{Performance on test set of development dataset}

\begin{comment}
Figure~\ref{fig:test_interval_match_dev} provides a comparison of the transferability of the inconclusive intervals 
from the validation set to the test set (development data) along the baseline and experimental methods.
The mean and standard deviation of observed inconclusive cases (PIncObs) in the test set 
is very similar across the baseline and experimental methods.
For each considered method the mean of the PIncObs hardly deviates from the identity line.
The similarity in data distribution of the validation and test set due to random splitting is an explanation for that.
\end{comment}

The performance comparison of the methods concerning the relative AUC for the mean balanced accuracy on conclusive cases
over the PIncObs in the test set is shown in Figure~\ref{fig:test_dev}.
In general, the CNN-based methods outperform both baseline methods, the SBR method and PCA-RFC.
The highest performance is achieved by the CNN-Regression (relative AUC: $99.23\%$) method 
whereas the lowest AUC is that for the SBR-based method (relative AUC: $96.38\%$).
The CNN-RLT method achieves slightly higher performance than the CNN-MVT.


% Method Comparison of obsInconclCases_inconclCasesValid - Development test set
\begin{figure}[ht]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_development.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_development.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_development.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_development.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_development.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on test set of development data. Transferability of inconclusive intervals..}
  \label{fig:test_interval_match_dev}
\end{figure}


% Method Comparison of bacc-obsInconclCases-concl - Development test set
\begin{figure}[ht]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_development.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_development.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_development.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_development.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_development.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on test set of development data. 
  Balanced accuracy over the percentage of observed inconclusive cases.}
  \label{fig:test_dev}
\end{figure}


% ------ PPMI --------

\subsubsection{Performance on PPMI dataset}


Figure~\ref{fig:test_ppmi} supports the performance comparison of the methods 
concerning the relative AUC for the mean balanced accuracy on conclusive cases over the PIncObs 
in the PPMI dataset.
Here also the CNN-based methods outperform both baseline methods, the SBR method and PCA-RFC.
The highest performance is achieved by the CNN-Regression (relative AUC: $99.38\%$) method 
whereas the lowest AUC is that for the SBR-based method (relative AUC: $97.51\%$).
The CNN-RLT method achieves slightly higher performance (relative AUC: $99.31\%$) than the CNN-MVT (relative AUC: $99.23\%$).



% Method Comparison of obsInconclCases_inconclCasesValid - PPMI
\begin{figure}[ht]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_ppmi.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_ppmi.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_ppmi.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_ppmi.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_ppmi.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on PPMI dataset. Transferability of inconclusive intervals.}
  \label{fig:test_interval_match_ppmi}
\end{figure}

% Method Comparison of bacc_obsInconclCases_concl - PPMI test set
\begin{figure}[ht]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_ppmi.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_ppmi.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_ppmi.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_ppmi.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_ppmi.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on PPMI dataset. 
  Balanced accuracy over the percentage of observed inconclusive cases.}
  \label{fig:test_ppmi}
\end{figure}


% ------ MPH --------

\subsubsection{Performance on MPH dataset}

In Figure~\ref{fig:test_mph} the performance comparison of the methods 
concerning the relative AUC for the mean balanced accuracy on conclusive cases over the PIncObs 
in the MPH dataset is presented.
As for the other test datasets, CNN-based methods outperform both baseline methods, the SBR method and PCA-RFC.
The highest performance is achieved by the CNN-Regression (relative AUC: $96.24\%$) method 
whereas the lowest AUC is that for the SBR-based method (relative AUC: $93.46\%$).
The CNN-RLT method achieves slightly higher performance (relative AUC: $96.12\%$) 
than the CNN-MVT (relative AUC: $95.73\%$).



% Method Comparison of obsInconclCases_inconclCasesValid - MPH
\begin{figure}[ht]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/obsInconclCases_inconclCasesValid_sbr_mph.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/obsInconclCases_inconclCasesValid_pca_rfc_mph.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/obsInconclCases_inconclCasesValid_baseline_majority_mph.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/obsInconclCases_inconclCasesValid_baseline_random_mph.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/obsInconclCases_inconclCasesValid_regression_mph.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on MPH dataset. Transferability of inconclusive intervals}
  \label{fig:test_interval_match_mph}
\end{figure}



% Method Comparison of bacc_obsInconclCases_concl - MPH test set
\begin{figure}[ht]
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/sbr/43/bacc_obsInconclCases_concl_sbr_mph.png}
    \subcaption{SBR method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/pca_rfc/43/bacc_obsInconclCases_concl_pca_rfc_mph.png}
    \subcaption{PCA-RFC method.}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_majority/43/bacc_obsInconclCases_concl_baseline_majority_mph.png}
    \subcaption{CNN method - MVT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/baseline_random/43/bacc_obsInconclCases_concl_baseline_random_mph.png}
    \subcaption{CNN method - RLT}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[width=1\textwidth]{content/figures/evaluations/regression/43/bacc_obsInconclCases_concl_regression_mph.png}
    \subcaption{CNN method - Regression}
  \end{subfigure}

  \caption{Comparison of different methods on MPH dataset.
  Balanced accuracy over the percentage of observed inconclusive cases.}
  \label{fig:test_mph}
\end{figure}


\subsection{Conclusion}

A concluding assessment of the performance of the methods 
concerning the relative AUC for the mean balanced accuracy on conclusive cases over the PIncObs 
can be regarded in Figure~\ref{fig:auc_comparison_methods_data}.
The CNN-based methods outperform the baseline, especially on the MPH dataset.
The best performance is achieved by the CNN-Regression method, followed by the CNN-RLT and CNN-MVT methods.


% AUC bAcc comparison of different methods and dataset
\begin{figure}[ht]
  \centering
  \includegraphics[width=1.0\textwidth]{content/figures/evaluations/auc_main_comparison.png}
  \caption{AUC achieved by baseline and experimental methods on different test data. 
  The AUC was calculated for the mean balanced accuracy over the percentage of inconclusive cases 
  in the considered test set.} 
  \label{fig:auc_comparison_methods_data}
\end{figure} 