\section{Introduction}
\label{sec:intro}

% PD - Statistics

Parkinson's disease (PD) is the second most common neurodegenerative disease after Alzheimer's disease [1]. 
It is expected to impose an increasing social and economic burden on societies as populations age [2]. 
The prevalence of PD in industrialized countries is about 1\% in people over 60 years of age [2]. 
The standardized incidence rate of PD is estimated to range between about 10 and about 20 per 100,000 person-years [2]. 
Thus, this results in the diagnosis of up to 100,000 new PD cases annually in the EU and up to 50,000 cases in the US.

% PD - Symptoms and diagnosis

PD is characterized by bradykinesia and variable expression of cardinal symptoms: resting tremor, rigidity, and postural instability [3, 4]. 
However, this combination of symptoms, often referred to as `parkinsonism' or `parkinsonian syndrome' (PS), 
occurs not only in PD (and some rare `atypical' neurodegenerative PS such as multiple system atrophy, progressive 
supranuclear palsy and corticobasal degeneration). 
It also occurs in so-called `secondary' (non-neurodegenerative) PS that can be induced by drugs, head trauma, 
inflammatory or metabolic disorder, as well as other diseases such as essential tremor, dystonic tremor, or normal pressure hydrocephalus [3, 5]. 
A particularly frequent cause of secondary PS is cerebrovascular disease [6]. 
The differentiation between PD and secondary PS is highly relevant, 
because secondary PS might be treated more effectively than PD and some secondary PS may be fully cured.
Yet, the clinical, that is, symptom-based differentiation between PD and secondary PS is challenging in a significant fraction of patients, 
particularly at early disease stages with mild symptoms and in patients with atypical presentation [7, 8]. 
These cases are often referred to as `clinical uncertain parkinsonian syndromes' (CUPS) [9].

% DAT-SPECT - An established procedure

DAT-SPECT with [$^{123}$I]FP-CIT is an established nuclear medicine brain imaging procedure for Parkinson's disease diagnosis.
The wide usage of the procedure is due to its high accuracy, its relevant impact on patient management, 
and the strong guideline recommendations.
In Europe about 70,000 patients are referred to DAT-SPECT per year, in Germany alone about 10,000, at UKE currently about 400 per year [22]. 
The demographical change in industrial countries is expected to result in a further increase in the number of DAT-SPECT examinations, 
because age is the major risk factor for PD [23]. 
Furthermore, there are early signs of PD such as smell loss and \textit{idiophatic} rapid eye movement sleep and behavioral disorder 
that can precede movement problems by several years, but are not particularly specific for PD [24-26]. 
It becomes increasingly important to detect PD at these early pre-motor stages, because the earlier the treatment is initiated the better 
the chances of moderating the course of PD with disease-modifying drugs[27].

% Automatic and accurate classification of DAT-SPECT desirable

In clinical practice, the interpretation of DAT-SPECT is binary, that is, the nuclear medicine physician has to decide whether the SPECT images 
indicate degeneration of the dopaminergic neurotransmitter system (Parkinson's disease) or not (secondary PS). 
This decision can be challenging by visual inspection of the tomographic SPECT images, particularly for less experienced readers [28]. 
Thus, DAT-SPECT would benefit from methods for the automatic classification of the images that achieve similar (or better) performance as experienced readers. 
Convolutional neural networks (CNNs) appear particularly promising for this purpose [29-47].

% Difficulty of classification of borderline cases

Yet, there are also `true' borderline cases that cannot be classified with high certainty even by expert readers. 
In DAT-SPECT of CUPS, the proportion of visually inconclusive borderline cases ranges between 5 and 10\% [48, 49]. 
Automatic binary classification of these cases by a CNN might pretend a certainty of the diagnosis that is not actually given. 
It is important, therefore, to identify these cases in order to make sure that the user visually inspects these SPECT images 
in order to check the automatic categorization particulary carefully. 
The user will accept the CNN's decision in some case, overrule the CNN in other cases, and will categorize the remaining cases as 
actually inconclusive (and might recommend follow-up DAT-SPECT after 6-12 months [50]). 

% Sigmoid output alone not suitable for identification of borderline cases

The most obvious approach to identify borderline cases in CNN-based classification would be based on the distance of the CNN's sigmoid output from a predefined decision threshold (e.g., 0.5). 
However, empirically, sigmoid outputs of CNN for classification of DAT-SPECT tend to cluster at the extreme values so that their utility for the identification of borderline cases seems limited.  
As a consequence, this approach is not recommended among practitioners, as it tends to overestimate the certainty of CNN-based classification [51-53].

% Aim of work and overview on the approach

Against this background, the current work aimed to propose and validate a CNN-based approach for the automatic classification of DAT-SPECT 
that allows reliable identification of inconclusive cases that might be misclassified by the CNN when the decision threshold is strictly applied.
The `decision confidence' of the classification model is evaluated on a metric, proposed in the following, 
that aims to maximize the classification performance of the model
while minimizing the potential effort of manual inspection originating from inconclusive cases.

Starting from the assumption that between-readers discrepancy in the binary visual interpretation of DAT-SPECT is much more likely in inconclusive cases 
than in conclusive cases, a standard CNN structure was trained for automatic classification of DAT-SPECT using a large training dataset in which each 
SPECT image had been visually classified by three independent readers. 
During the model training phase, the standard-of-truth label was selected randomly from the three independent available reads. 
This way, the same inconclusive image could be presented to the network with different standard-of-truth labels. 
The rationale was that this could allow the network to learn about the uncertainty of these cases, 
and that this would result in sigmoid outputs close to the decision threshold.

This “random label” training (RLT) approach was compared with the conventional majority vote training (MVT) approach. 
In the latter,  the majority vote across the three readers was consistently used as standard-of-truth during the training phase. 
The MVT obviously “hides” the uncertainty associated with between-readers discrepancy from the network. 

To be able to better assess the performance of the CNN-based approaches, univariate and multivariate conventional methods were employed as 
benchmark methods. In addition, the performance of the approaches is also evaluated on independent external datasets.

% Hypotheses

% 1st hypothesis
The primary hypothesis put to test in this work was that the sigmoid output of the CNN is more effective for the identification of inconclusive cases 
(by an `inconclusive' range around the decision threshold) when the network is trained using the RLT strategy compared to MVT.

To test this hypothesis, the proportion of inconclusive cases required to achieve a given balanced accuracy in the conclusive cases 
was proposed and used as a performance metric.
More precisely, the area under the curve (AUC) of mean balanced accuracy in conclusive cases versus the mean proportion of inconclusive cases 
(observed in the test set) was used as a model-agnostic quality metric. 
The AUC does not depend on a specific operating point (target balanced accuracy).  
The rationale for this performance metric is that more inconclusive cases would require more attention and manual inspection 
by the attending physician which is considered `expensive'
(“90\% inconclusive cases to achieve the required accuracy in the remaining 10\% of cases is clearly useless”).
Therefore the utility of the classifier for widespread use in clinical practice depends on its `decision confidence', 
e.g. the proportion of inconclusive cases to be accepted to achieve a predefined balanced accuracy in the remaining conclusive cases. 

% 2nd hypothesis
The following secondary hypotheses were put to test. 
First, CNN-based classification outperforms conventional baseline methods in terms of AUC of balanced accuracy, 
both univariate and multivariate baseline methods. 
The specific binding ratio (SBR) of the tracer uptake in the putamen was used for the univariate analysis as a benchmark method.
Current procedure guidelines recommend the putaminal SBR to support the visual interpretation of DAT-SPECT in everyday clinical patient care [54]. 
The putaminal SBR characterizes the contrast of the tracer uptake (= intensity) in the putamen relative to the mean tracer uptake in a reference 
region void of DAT [55]. 
The putaminal SBR is assumed to be proportional to the density of DAT in the putamen [55]. 
As a multivariate benchmark method, a random forest approach was implemented using the expression profile of a set of covariance patterns as input. 
The covariance patterns were identified by principal component analysis in the training dataset. 

% 3rd hypothesis
Second, CNN-based classification demonstrates enhanced generalizability, such as being more robust regarding varying image characteristics 
(e.g., spatial resolution) 
associated with the use of different acquisition hardware 
(different SPECT cameras, different collimators\dots) 
and different reconstruction and correction methods (application of resolution recovery, application of attenuation correction\dots). 
To test this hypothesis, the classification methods were compared in two test datasets fully independent of the training dataset.

% Summary of research questions

The following research questions are addressed: 
\begin{itemize}
    \item When comparing the CNN-based approaches, how does the RLT approach perform compared to the MVT approach? 
    Is the performance metric proposed in this work practically suitable for the comparison of different approaches?

    \item How do the CNN-based approaches perform on diverse testing data compared to conventional approaches?
    What conclusions can be made regarding the generalizability of the approaches under test?
    
\end{itemize}

% Thesis structure

\textit{Include thesis structure paragraph.}

